{"cells":[{"cell_type":"markdown","metadata":{"id":"4LyHDS0r64Po"},"source":["# Reformat Model\n","\n","Reformat the \"best\" model to intake matrices of beta, b, gamma. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1309,"status":"ok","timestamp":1659392554399,"user":{"displayName":"Maria Carilli","userId":"16432364565729704460"},"user_tz":420},"id":"aDkel2eaPXND","outputId":"e2e60149-79dd-4ab2-fc84-b99e06ccbcd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/scBIVI_mc/scBIVI/scBIVI\n"]}],"source":["# # mount to drive and change directory\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# %cd /content/drive/MyDrive/scBIVI_mc/scBIVI/scBIVI/"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import sys\n","sys.path.append('../')\n","import matplotlib.pyplot as plt\n","from scipy import stats"],"metadata":{"id":"Hu1p6FvoIWle"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define model "],"metadata":{"id":"MniEOSVWJH6T"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","\n","    def __init__(self, input_dim, npdf, h1_dim, h2_dim):\n","        super().__init__()\n","\n","        self.input = nn.Linear(input_dim, h1_dim)\n","        self.hidden = nn.Linear(h1_dim, h2_dim)\n","        self.output = nn.Linear(h2_dim, npdf)\n","\n","        self.hyp = nn.Linear(h1_dim,1)\n","\n","        self.softmax = nn.Softmax(dim=1)\n","        self.sigmoid = torch.sigmoid\n","        \n","\n","    def forward(self, inputs):\n","\n","        # pass inputs to first layer, apply sigmoid\n","        l_1 = self.sigmoid(self.input(inputs))\n","\n","        # pass to second layer, apply sigmoid\n","        l_2 = self.sigmoid(self.hidden(l_1))\n","        \n","        # pass to output layer \n","        w_un = (self.output(l_2))\n","        \n","        # pass out hyperparameter, sigmoid so it is between 0 and 1, then scale between 1 and 6\n","        hyp = self.sigmoid(self.hyp(l_2))\n","    \n","        # apply softmax\n","        w_pred = self.softmax(w_un)\n","\n","        return w_pred,hyp\n","        \n","\n","model_path = './models/best_model_MODEL'       \n","npdf = 10\n","\n","# load in model\n","model = MLP(7,10,256,256)\n","model.load_state_dict(torch.load(model_path))\n","model.eval() \n","model.to(torch.device('cuda'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"0gg1fXbnJHLa","executionInfo":{"status":"error","timestamp":1659392558087,"user_tz":420,"elapsed":798,"user":{"displayName":"Maria Carilli","userId":"16432364565729704460"}},"outputId":"35615dc2-a745-4f32-9a1b-7a0aa216f126"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ab4b28204409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"]}]},{"cell_type":"code","source":["def get_NORM(npdf,quantiles='cheb'):\n","    '''' Returns quantiles based on the number of kernel functions npdf. \n","    Chebyshev or linear, with chebyshev as default.\n","    '''\n","    if quantiles == 'lin':\n","        q = np.linspace(0,1,npdf+2)[1:-1]\n","        norm = stats.norm.ppf(q)\n","        norm = torch.tensor(norm)\n","        return norm\n","    if quantiles == 'cheb':\n","        n = np.arange(npdf)\n","        q = np.flip((np.cos((2*(n+1)-1)/(2*npdf)*np.pi)+1)/2)\n","\n","        norm = stats.norm.ppf(q)\n","        norm = torch.tensor(norm)\n","        return norm\n","\n","NORM = get_NORM(10)"],"metadata":{"id":"5pav8B06Ifby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_grid(logmean_cond,logstd_cond,NORM):\n","    ''' Generate grid of kernel means based on the log mean and log standard devation of a conditional distribution.\n","    Generates the grid of quantile values in NORM, scaled by conditional moments.\n","    '''\n","    logmean_cond = torch.reshape(logmean_cond,(-1,1))\n","    logstd_cond = torch.reshape(logstd_cond,(-1,1))\n","    translin = torch.exp(torch.add(logmean_cond,logstd_cond*NORM))\n","    \n","    return translin\n","\n","def get_ypred_at_RT(p,w,hyp,n,m,NORM,eps=1e-8):\n","    '''Given a parameter vector (tensor) and weights (tensor), and hyperparameter,\n","    calculates ypred (Y), or approximate probability. Calculates over array of nascent (n) and mature (m) values.\n","    '''\n","        \n","    p_vec = 10**p[:,0:3]\n","    logmean_cond = p[:,3]\n","    logstd_cond = p[:,4]\n","    \n","    hyp = hyp*5+1\n","        \n","    grid = generate_grid(logmean_cond,logstd_cond,NORM)\n","    s = torch.zeros((len(n),10))\n","    s[:,:-1] = torch.diff(grid,axis=1)\n","    s *= hyp\n","    s[:,-1] = torch.sqrt(grid[:,-1])\n","  \n","    \n","    v = s**2\n","    r = grid**2/(v-grid)\n","    p_nb = 1-grid/v\n","    \n","    Y = torch.zeros((len(n),1))\n","\n","    # grid_i = grid[:,i].reshape((-1,1))\n","\n","    # r = r[:,i]\n","    # w = w[:,i].reshape((-1,1))\n","    # p_nb = p_nb[:,i]\n","\n","\n","    y_ = m * torch.log(grid + eps) - grid - torch.lgamma(m+1) \n","\n","    if (p_nb > 1e-10).any():\n","      index = [p_nb > 1e-10]\n","      y_[index] += torch.special.gammaln(grid[index]+r[index]) - torch.special.gammaln(r[index]) \\\n","                - grid[index]*torch.log(r[index] + grid[index]) + grid[index] \\\n","                + r[index]*torch.log(r[index]/(r[index]+grid[index]))\n","\n","    y_ = torch.exp(y_)\n","    y_weighted = w*y_\n","    Y = y_weighted.sum(axis=1)\n","\n","    EPS = 1e-40\n","    Y[Y<EPS]=EPS\n","    return Y"],"metadata":{"id":"ok7d2Zw4JmBx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def log_prob_nnNB(x: torch.Tensor, mu1: torch.Tensor, mu2: torch.Tensor,\n","                       theta: torch.Tensor,  THETA_IS, eps=1e-8, **kwargs):\n","    ''' Calculates probability for bursty model given our most accurate model.\n","      -----------------------------------\n","      x\n","        data\n","     mu1,mu2\n","        mean of the negative binomial (has to be positive support) (shape: minibatch x vars/2)\n","      theta\n","        params (has to be positive support) (shape: minibatch x vars)\n","      eps\n","        numerical stability constant\n","    '''\n","    # Divide the original data x into spliced (x) and unspliced (y)\n","    n,m = torch.chunk(x,2,dim=-1)\n","\n","    if THETA_IS == 'MAT_SHAPE':\n","        gamma = 1/theta\n","        b = mu2*gamma\n","        beta = b/mu1\n","    elif THETA_IS == 'B':\n","        print('hasdakdhakjsd')\n","        b = theta\n","        beta = b/mu1\n","        gamma = b/mu2\n","    elif THETA_IS == 'NAS_SHAPE':\n","        beta = 1/theta\n","        b = mu1*beta\n","        gamma = b/mu2\n","    \n","    # calculate nascent marginal negative binomial P(n) \n","    n_nb = 1/beta\n","    p_nb = 1/(b+1)\n","    prob_nascent = torch.tensor(stats.nbinom.pmf(k=n, n=n_nb, p=p_nb))\n"," \n","  \n","    # get moments\n","    var1 = mu1 * (1+b)\n","    var2 = mu2 * (1+b*beta/(beta+gamma))\n","    cov = b**2/(beta+gamma)\n","    \n","    # calculate conditional moments\n","    logvar1 = torch.log((var1/mu1**2)+1)\n","    logvar2 = torch.log((var2/mu2**2)+1)\n","    logstd1 = torch.sqrt(logvar1)\n","    logstd2 = torch.sqrt(logvar2)\n","\n","    logmean1 = torch.log(mu1**2/torch.sqrt(var1+mu1**2))\n","    logmean2 = torch.log(mu2**2/torch.sqrt(var2+mu2**2))\n","\n","    val = (logmean1 + logmean2 + (logvar1 + logvar2)/2)\n","    val[val<-88] = -88\n","    logcov = torch.log(cov * torch.exp(-(val)) +1 )\n","    logcorr = logcov/torch.sqrt(logvar1 * logvar2)\n","\n","    logmean_cond = logmean2 + logcorr * logstd2/logstd1 * (torch.log(n+1) - logmean1)\n","    logvar_cond = logvar2 * (1-logcorr**2)  \n","    logstd_cond = logstd2 * torch.sqrt(1-logcorr**2)  \n","\n","    xmax_m = torch.ceil(torch.ceil(mu2) + 4*torch.sqrt(var2))\n","    xmax_m = torch.clip(xmax_m,30,np.inf).int()\n","\n","    # reshape and stack\n","    pv = torch.column_stack((torch.log10(b).reshape(-1),\n","                             torch.log10(beta).reshape(-1),\n","                             torch.log10(gamma).reshape(-1),\n","                             logmean_cond.reshape(-1),\n","                             logstd_cond.reshape(-1),\n","                             xmax_m.reshape(-1),\n","                             n.reshape(-1)\n","                             ))\n","    # run through model\n","    w_,hyp_= model(pv)\n","\n","    n = n.reshape(-1,1)\n","    m = m.reshape(-1,1)\n","    # get conditional probabilites\n","    ypred_cond = get_ypred_at_RT(pv,w_,hyp_,n,m,NORM)\n","    \n","    # multiply conditionals P(m|n) by P(n)\n","    predicted = prob_nascent * ypred_cond.reshape((prob_nascent.shape))\n","    log_P = torch.log(predicted)\n","    \n","    return(predicted)"],"metadata":{"id":"rWkNSlpCJvCY","executionInfo":{"status":"error","timestamp":1659455666853,"user_tz":420,"elapsed":330,"user":{"displayName":"Maria Carilli","userId":"16432364565729704460"}},"colab":{"base_uri":"https://localhost:8080/","height":236},"outputId":"5ccf88d2-d7de-4581-fcbe-020c2b4f9283"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2a425a1c64e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m def get_prob_nnNB(x: torch.Tensor, mu1: torch.Tensor, mu2: torch.Tensor,\n\u001b[0;32m----> 2\u001b[0;31m                        theta: torch.Tensor, eps=1e-8, **kwargs):\n\u001b[0m\u001b[1;32m      3\u001b[0m     ''' Calculates probability for bursty model given our most accurate model.\n\u001b[1;32m      4\u001b[0m       \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"73HaeRAbgRg_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"reformat_model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}