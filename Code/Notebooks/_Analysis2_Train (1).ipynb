{"cells":[{"cell_type":"markdown","metadata":{"id":"4LyHDS0r64Po"},"source":["# Train 6 standard models on various datasets\n","\n","This notebook will continue functions to train and store results needed for analysis. \n","\n","\n","It will compare models\n","\n","1. Bursty model of transcription (nnNB), full data\n","2. Constitutive model of transcription (Poisson), full data\n","3. Bivariate negative binomial model (BVNB), full data\n","4. vanilla scVI, spliced data\n","5. vanilla scVI, unspliced data\n","6. vanilla scVI, full data\n","\n","For an input data set. \n","\n","\n","It will output and store a results dictionary that contains for each of the six setups:\n","\n","1. X_scVI: latent space\n","2. reconstructed parameters: means and dispersions\n","3. reconstruction loss over training epochs test/valid\n","5. final reconstruction loss on train/test data\n","4. runtime\n","\n","\n","\n","\n","Analysis functions are not included in this training notebook. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16772,"status":"ok","timestamp":1665091829735,"user":{"displayName":"Maria Carilli","userId":"07753124307568175110"},"user_tz":420},"id":"Dx9K8ecWF2FN","outputId":"18397fb0-b943-41f0-c994-0641d6239ddc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/grad/scBIVI/GCCCP_2021/Code/Notebooks\n"]}],"source":["# mount drive \n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/grad/scBIVI/GCCCP_2021/Code/Notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOMjTFRNFv0S"},"outputs":[],"source":["# clone the repo -- private right now -- if necessary\n","#!git clone https://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@github.com/pachterlab/GCCCP_2021.git -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjOTtMjv63GY"},"outputs":[],"source":["# install necessary pacakges\n","%%capture\n","%pip install scanpy \n","%pip install scvi-tools==0.8.1\n","%pip install loompy\n","%pip install leidenalg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2099,"status":"ok","timestamp":1665091861095,"user":{"displayName":"Maria Carilli","userId":"07753124307568175110"},"user_tz":420},"id":"YTE6OfMK9PKZ","outputId":"ca8f59f3-0be8-44c7-a945-5324e710cc82"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","1\n","0\n"]}],"source":["# check GPU availability\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","memory_used = torch.cuda.memory_allocated()\n","print(torch.cuda.is_available())\n","print(torch.cuda.device_count())\n","print(torch.cuda.current_device())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pkgIX6swDe9"},"outputs":[],"source":["# System\n","import time, gc\n","\n","# add module paths to sys path\n","import sys\n","sys.path.insert(0,'../custom_distributions/')\n","sys.path.insert(0, '../BIVAE/')\n","\n","# Math\n","import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.model_selection import StratifiedKFold\n","\n","# to save results\n","import pickle\n","\n","\n","# scvi\n","import anndata\n","import scvi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7682,"status":"ok","timestamp":1665091873071,"user":{"displayName":"Maria Carilli","userId":"07753124307568175110"},"user_tz":420},"id":"JsCFILc9CiWj","outputId":"e1aa28f3-630a-43b2-cbeb-df3a5b426388"},"outputs":[{"name":"stdout","output_type":"stream","text":["reload baby\n"]}],"source":["# import scbivi scripts\n","import scBIVI\n","import nnNB_module\n","import custom_distributions\n","\n","# set the model to cuda\n","nnNB_module.model.to(torch.device('cuda'))\n","NORM = nnNB_module.NORM.to(torch.device('cuda'))"]},{"cell_type":"markdown","metadata":{"id":"r0lQ5lR7XUHd"},"source":["# Load in data \n","\n","\n","Change data name to test out different simulated datasets with varying number of celltypes. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6004,"status":"ok","timestamp":1665091879064,"user":{"displayName":"Maria Carilli","userId":"07753124307568175110"},"user_tz":420},"id":"SHnXm3Pq6WCU","outputId":"be89c4f1-9aba-4fe8-d077-edfa211a07ca"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n","  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"]}],"source":["name = 'const_5ct'\n","\n","# change to hdf5 file if that is what you store data as\n","adata = anndata.read_loom(f'../data/simulated_data/{name}.loom')\n","\n","if 'gene_name' in adata.var.columns:\n","    adata.var_names = adata.var['gene_name'].to_list()\n","\n","# can change as necessary for data. \n","adata.obs['Cluster'] = adata.obs['Cell Type']\n","adata.var_names_make_unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1665091879065,"user":{"displayName":"Maria Carilli","userId":"07753124307568175110"},"user_tz":420},"id":"HK2C7K5JKdFv","outputId":"e0821534-35fe-4f99-9050-ebc6a8bc5789"},"outputs":[{"data":{"text/plain":["AnnData object with n_obs × n_vars = 6000 × 4000\n","    obs: 'Cell Type', 'obs_names', 'Cluster'\n","    var: 'Marker Annotation', 'Spliced', 'var_names'\n","    layers: 'counts'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["adata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxjYlTsdc9vO"},"outputs":[],"source":["#Set up train/test data splits with 5-fold split\n","skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n","skf_splits = skf.split(adata, adata.obs['Cluster'])\n","\n","# Use last of the K-fold splits\n","for k, (train_index, test_index) in enumerate(skf_splits):\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1665091879066,"user":{"displayName":"Maria Carilli","userId":"07753124307568175110"},"user_tz":420},"id":"0tRntI7mxGXc","outputId":"70415db8-f784-4d08-96bb-870a6c9a674c"},"outputs":[{"name":"stdout","output_type":"stream","text":["training on 4800 cells, testing on 1200 cells\n"]}],"source":["print(f'training on {len(train_index)} cells, testing on {len(test_index)} cells')"]},{"cell_type":"markdown","metadata":{"id":"TuWAkvshCjua"},"source":["-----\n","\n","\n","# Define training function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoSUe5ih2f0F"},"outputs":[],"source":["# if anything goes wrong in training, this will catch where it happens\n","torch.autograd.set_detect_anomaly(True)\n","\n","\n","# compare setups\n","def compare_setups(adata, setups, results_dict, hyperparameters, train_index = train_index, test_index = test_index):\n","  ''' Runs scBIVI on adata for listed setups in setups given hyperparameters, stores outputs in results_dict. \n","      Train index and test index are defined globally -- could be nice to pass these in as well? \n","  ''' \n","\n","  lr = hyperparameters['lr']\n","  n_epochs = hyperparameters['n_epochs']\n","  n_hidden = hyperparameters['n_hidden']\n","  n_layers = hyperparameters['n_layers']\n","\n","  \n","  for setup in setups:\n","    print(setup)\n","    method,n_latent,constant, = setup.split(\"-\")\n","    n_latent = int(n_latent)\n","\n","    # test using only spliced or unspliced in vanilla scVI\n","    if '.S' in method:\n","      adata_in = adata[:,adata.var['Spliced']==1].copy()\n","      print('spliced')\n","    elif '.U' in method:\n","      adata_in = adata[:,adata.var['Spliced']==0].copy()\n","      print('unspliced')\n","    else:\n","      adata_in = adata.copy()\n","\n","    print(adata_in.X.shape)\n","    scvi.data.setup_anndata(adata_in, layer=\"counts\")\n","\n","    \n","    train_adata, test_adata = adata_in[train_index], adata_in[test_index]\n","    train_adata = train_adata.copy()\n","\n","    ## Set model parameters\n","    model_args = {'use_cuda'     : True,\n","                  'n_latent'     : n_latent,\n","                  'n_layers'     : n_layers,\n","                  'dispersion'   : 'gene',\n","                  'n_hidden'     : n_hidden,\n","                  'dropout_rate' :  0.1,\n","                  'gene_likelihood'    :  'nb',\n","                  'log_variational'    :  True,\n","                  'latent_distribution':  'normal'\n","                  }\n","    #model_args.update(additional_kwargs)\n","\n","    ## Create model\n","    if method == 'NBcorr':\n","        model = scBIVI.scBIVI(train_adata,mode='corr',**model_args)\n","    elif method == 'NBuncorr':\n","        model = scBIVI.scBIVI(train_adata,mode='uncorr',**model_args)\n","    elif method == 'Poisson':\n","        custom_dist = lambda x,mu1,mu2,theta,eps : custom_distributions.log_prob_poisson(x,mu1,mu2,theta,eps,THETA_IS = constant)\n","        model = scBIVI.scBIVI(train_adata,mode='custom',custom_dist=custom_dist,**model_args)\n","    elif method == 'nnNB':\n","        custom_dist = lambda x,mu1,mu2,theta,eps : nnNB_module.log_prob_nnNB(x,mu1,mu2,theta,eps,THETA_IS = constant,\n","                                                                             model= nnNB_module.model.to(torch.device('cuda')),\n","                                                                             norm = NORM)\n","        model = scBIVI.scBIVI(train_adata,mode='custom',custom_dist=custom_dist,**model_args)\n","    elif method == 'vanilla.U':\n","      model = scvi.model.SCVI(train_adata,**model_args)\n","    elif method == 'vanilla.S':\n","      model = scvi.model.SCVI(train_adata,**model_args)\n","    elif method == 'vanilla.full':\n","      model = scvi.model.SCVI(train_adata,**model_args)\n","    elif method == 'vanilla.U.P':\n","      model_args['gene_likelihood'] = 'poisson'\n","      model = scvi.model.SCVI(train_adata,**model_args)\n","    elif method == 'vanilla.S.P':\n","      model_args['gene_likelihood'] = 'poisson'\n","      model = scvi.model.SCVI(train_adata,**model_args)\n","    elif method == 'vanilla.full.P':\n","      model_args['gene_likelihood'] = 'poisson'\n","      model = scvi.model.SCVI(train_adata,**model_args)\n","    else:\n","        raise Exception('Input valid scVI model')\n","\n","    ## Train model\n","    start = time.time()\n","    model.train(n_epochs = n_epochs,\n","                lr       = lr,\n","                n_epochs_kl_warmup = n_epochs/2,\n","                metrics_to_monitor = ['reconstruction_error'],\n","                frequency = 1,\n","                train_size = 0.9)\n","\n","    runtime     = time.time() - start\n","    memory_used = torch.cuda.memory_allocated()\n","    results_dict[setup]['runtime'].append(runtime)\n","\n","    ## Save training history\n","    df_history = {'reconstruction_error_test_set' : model.history['reconstruction_error_test_set'],\n","                  'reconstruction_error_train_set': model.history['reconstruction_error_train_set']}\n","    df_history = pd.DataFrame(df_history)\n","    df_history = pd.DataFrame(df_history.stack())\n","    df = df_history\n","    df.reset_index(inplace=True)\n","    df.columns = ['Epoch','Loss Type', 'Loss']\n","    results_dict[setup]['df_history'] = df\n","\n","    ## Get reconstruction loss on test data\n","    test_error  = model.get_reconstruction_error(test_adata)\n","    train_error = model.get_reconstruction_error(train_adata)\n","    results_dict[setup]['recon_error'].append(np.array([train_error,test_error]))\n","\n","\n","    results_dict[setup]['params'] = model.get_likelihood_parameters(adata_in)\n","\n","    ## Extract the embedding space for scVI\n","    X_out_full = model.get_latent_representation(adata_in)\n","\n","    adata.obsm[f'X_{method}'] = X_out_full\n","    results_dict[setup][f'X_{n_latent}'] = X_out_full\n","\n","    del model\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","  \n","  return(results_dict,adata)"]},{"cell_type":"markdown","metadata":{"id":"spZ0k7hG918d"},"source":["# Compare Distributions\n","\n","\n","Can change various training hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvsaCvPX98Ec"},"outputs":[],"source":["#seed should not matter, but this seed works well\n","# scvi._settings.ScviConfig.seed=(8675309)\n","# torch.manual_seed(8675309)\n","# # np.seed(8675309)\n","# np.random.seed(8675309)\n","\n","# Hyper-parameters\n","hyperparameters = { 'lr'       : 1e-3,\n","        'n_epochs' : 100, \n","        'n_hidden' : 128,\n","        'n_layers' : 3 }\n","\n","z  = 10\n","constant = 'NAS_SHAPE'\n","\n","setups = [\n","          f'vanilla.U-{z}-{constant}',\n","          f'vanilla.S-{z}-{constant}',\n","          f'vanilla.full-{z}-{constant}',\n","          f'vanilla.U.P-{z}-{constant}',\n","          f'vanilla.S.P-{z}-{constant}',\n","          f'vanilla.full.P-{z}-{constant}',\n","          f'Poisson-{z}-{constant}',\n","          f'NBcorr-{z}-{constant}',\n","          f'nnNB-{z}-{constant}'\n","          ]\n","\n","metrics_list = [f'X_{z}','runtime','df_history','params','recon_error']\n","results_dict = {setup:{metrics: [] for metrics in metrics_list} for setup in setups}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uiv2Tvnh-I2k","outputId":"87f0b79d-b582-4f9b-b866-27d9d83b95e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Poisson-10-NAS_SHAPE\n","(6000, 4000)\n","\u001b[34mINFO    \u001b[0m No batch_key inputted, assuming all cells are same batch                                                  \n","\u001b[34mINFO    \u001b[0m No label_key inputted, assuming all cells have same label                                                 \n","\u001b[34mINFO    \u001b[0m Using data from adata.layers\u001b[1m[\u001b[0m\u001b[32m\"counts\"\u001b[0m\u001b[1m]\u001b[0m                                                                    \n","\u001b[34mINFO    \u001b[0m Computing library size prior per batch                                                                    \n","\u001b[34mINFO    \u001b[0m Successfully registered anndata object containing \u001b[1;36m6000\u001b[0m cells, \u001b[1;36m4000\u001b[0m vars, \u001b[1;36m1\u001b[0m batches, \u001b[1;36m1\u001b[0m labels, and \u001b[1;36m0\u001b[0m       \n","         proteins. Also registered \u001b[1;36m0\u001b[0m extra categorical covariates and \u001b[1;36m0\u001b[0m extra continuous covariates.               \n","\u001b[34mINFO    \u001b[0m Please do not further modify adata until model is trained.                                                \n","\u001b[34mINFO    \u001b[0m Training for \u001b[1;36m100\u001b[0m epochs                                                                                   \n","\u001b[34mINFO    \u001b[0m KL warmup for \u001b[1;36m50.0\u001b[0m epochs                                                                                 \n","Training...: 100%|██████████| 100/100 [05:04<00:00,  3.05s/it]\n","\u001b[34mINFO    \u001b[0m Training time:  \u001b[1;36m265\u001b[0m s. \u001b[35m/\u001b[0m \u001b[1;36m100\u001b[0m epochs                                                                       \n","\u001b[34mINFO    \u001b[0m Received view of anndata, making copy.                                                                    \n","nnNB-10-NAS_SHAPE\n","(6000, 4000)\n","\u001b[34mINFO    \u001b[0m No batch_key inputted, assuming all cells are same batch                                                  \n","\u001b[34mINFO    \u001b[0m No label_key inputted, assuming all cells have same label                                                 \n","\u001b[34mINFO    \u001b[0m Using data from adata.layers\u001b[1m[\u001b[0m\u001b[32m\"counts\"\u001b[0m\u001b[1m]\u001b[0m                                                                    \n","\u001b[34mINFO    \u001b[0m Computing library size prior per batch                                                                    \n","\u001b[34mINFO    \u001b[0m Successfully registered anndata object containing \u001b[1;36m6000\u001b[0m cells, \u001b[1;36m4000\u001b[0m vars, \u001b[1;36m1\u001b[0m batches, \u001b[1;36m1\u001b[0m labels, and \u001b[1;36m0\u001b[0m       \n","         proteins. Also registered \u001b[1;36m0\u001b[0m extra categorical covariates and \u001b[1;36m0\u001b[0m extra continuous covariates.               \n","\u001b[34mINFO    \u001b[0m Please do not further modify adata until model is trained.                                                \n","\u001b[34mINFO    \u001b[0m Training for \u001b[1;36m100\u001b[0m epochs                                                                                   \n","\u001b[34mINFO    \u001b[0m KL warmup for \u001b[1;36m50.0\u001b[0m epochs                                                                                 \n","Training...: 100%|██████████| 100/100 [24:11<00:00, 14.51s/it]\n","\u001b[34mINFO    \u001b[0m Training time:  \u001b[1;36m1129\u001b[0m s. \u001b[35m/\u001b[0m \u001b[1;36m100\u001b[0m epochs                                                                      \n","\u001b[34mINFO    \u001b[0m Received view of anndata, making copy.                                                                    \n"]}],"source":["results_dict, adata = compare_setups(adata, setups,results_dict,hyperparameters)\n","results_dict['Cell Type'] = adata.obs['Cell Type']"]},{"cell_type":"markdown","metadata":{"id":"qSfIMlvXHZlr"},"source":["# Save results dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFCx90x8LNOV"},"outputs":[],"source":["results_file = open(f\"../results/{name}_results_dict.pickle\", \"wb\")\n","pickle.dump(results_dict, results_file)\n","results_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2gBcem9JF30"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}