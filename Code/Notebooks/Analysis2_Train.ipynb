{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LyHDS0r64Po"
   },
   "source": [
    "# Train Models on Various Datasets\n",
    "\n",
    "This notebook will continue functions to train and store results needed for analysis. \n",
    "\n",
    "\n",
    "It will compare models\n",
    "\n",
    "1. Bursty model of transcription (nnNB), full data\n",
    "2. Constitutive model of transcription (Poisson), full data\n",
    "3. Bivariate negative binomial model (BVNB), full data\n",
    "4. vanilla scVI, spliced data\n",
    "5. vanilla scVI, unspliced data\n",
    "6. vanilla scVI, full data\n",
    "7. Poisson scVI, spliced data\n",
    "8. Poisson scVI, unspliced data\n",
    "9. Poisson scVI, full data\n",
    "\n",
    "For an input data set. \n",
    "\n",
    "\n",
    "It will output and store a results dictionary that contains for each of the six setups:\n",
    "\n",
    "1. X_scVI: latent space\n",
    "2. reconstructed parameters: means and dispersions\n",
    "3. reconstruction loss over training epochs test/valid\n",
    "5. final reconstruction loss on train/test data\n",
    "4. runtime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Analysis functions are not included in this training notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16772,
     "status": "ok",
     "timestamp": 1665091829735,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "Dx9K8ecWF2FN",
    "outputId": "18397fb0-b943-41f0-c994-0641d6239ddc"
   },
   "outputs": [],
   "source": [
    "# mount drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd drive/MyDrive/grad/scBIVI/GCCCP_2021/Code/Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOMjTFRNFv0S"
   },
   "outputs": [],
   "source": [
    "# clone the repo -- private right now -- if necessary\n",
    "#!git clone https://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@github.com/pachterlab/GCCCP_2021.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NjOTtMjv63GY"
   },
   "outputs": [],
   "source": [
    "# install necessary pacakges\n",
    "# %%capture\n",
    "!pip install scanpy -q\n",
    "!pip install scvi-tools==0.8.1 -q\n",
    "!pip install loompy -q\n",
    "!pip install leidenalg -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2099,
     "status": "ok",
     "timestamp": 1665091861095,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "YTE6OfMK9PKZ",
    "outputId": "ca8f59f3-0be8-44c7-a945-5324e710cc82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check GPU availability\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "memory_used = torch.cuda.memory_allocated()\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9pkgIX6swDe9"
   },
   "outputs": [],
   "source": [
    "# System\n",
    "import time, gc\n",
    "\n",
    "# add module paths to sys path\n",
    "import sys\n",
    "sys.path.insert(0,'../custom_distributions/')\n",
    "sys.path.insert(0, '../BIVAE/')\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# to save results\n",
    "import pickle\n",
    "\n",
    "# scvi\n",
    "import anndata\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7682,
     "status": "ok",
     "timestamp": 1665091873071,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "JsCFILc9CiWj",
    "outputId": "e1aa28f3-630a-43b2-cbeb-df3a5b426388"
   },
   "outputs": [],
   "source": [
    "# import scbivi scripts\n",
    "import scBIVI\n",
    "import nnNB_module\n",
    "import custom_distributions\n",
    "\n",
    "# set the model to cuda\n",
    "nnNB_module.model.to(torch.device('cuda'))\n",
    "NORM = nnNB_module.NORM.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0lQ5lR7XUHd"
   },
   "source": [
    "# Load in data \n",
    "\n",
    "\n",
    "Change data name to test out different simulated datasets with varying number of celltypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6004,
     "status": "ok",
     "timestamp": 1665091879064,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "SHnXm3Pq6WCU",
    "outputId": "be89c4f1-9aba-4fe8-d077-edfa211a07ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "#name = 'const_15ct'\n",
    "\n",
    "# change to hdf5 file if that is what you store data as\n",
    "adata = anndata.read_loom(f'../data/allen/B08_processed_hv.loom')\n",
    "\n",
    "if 'gene_name' in adata.var.columns:\n",
    "    adata.var_names = adata.var['gene_name'].to_list()\n",
    "\n",
    "# can change as necessary for data. \n",
    "adata.obs['Cluster'] = adata.obs['Cell Type']\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dxjYlTsdc9vO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scikit_learn-1.0.1-py3.8-linux-x86_64.egg/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Set up train/test data splits with 5-fold split\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "skf_splits = skf.split(adata, adata.obs['Cluster'])\n",
    "\n",
    "# Use last of the K-fold splits\n",
    "for k, (train_index, test_index) in enumerate(skf_splits):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1665091879066,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "0tRntI7mxGXc",
    "outputId": "70415db8-f784-4d08-96bb-870a6c9a674c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 6740 cells, testing on 1684 cells\n"
     ]
    }
   ],
   "source": [
    "print(f'training on {len(train_index)} cells, testing on {len(test_index)} cells')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuWAkvshCjua"
   },
   "source": [
    "-----\n",
    "\n",
    "\n",
    "# Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DoSUe5ih2f0F"
   },
   "outputs": [],
   "source": [
    "# if anything goes wrong in training, this will catch where it happens\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# compare setups\n",
    "def compare_setups(adata, setups, results_dict, hyperparameters, train_index = train_index, test_index = test_index):\n",
    "  ''' Runs scBIVI on adata for listed setups in setups given hyperparameters, stores outputs in results_dict. \n",
    "      Train index and test index are defined globally -- could be nice to pass these in as well? \n",
    "  ''' \n",
    "\n",
    "  lr = hyperparameters['lr']\n",
    "  n_epochs = hyperparameters['n_epochs']\n",
    "  n_hidden = hyperparameters['n_hidden']\n",
    "  n_layers = hyperparameters['n_layers']\n",
    "\n",
    "  \n",
    "  for setup in setups:\n",
    "    print(setup)\n",
    "    method,n_latent,constant, = setup.split(\"-\")\n",
    "    n_latent = int(n_latent)\n",
    "\n",
    "    # test using only spliced or unspliced in vanilla scVI\n",
    "    if '.S' in method:\n",
    "      adata_in = adata[:,adata.var['Spliced']==1].copy()\n",
    "      print('spliced')\n",
    "    elif '.U' in method:\n",
    "      adata_in = adata[:,adata.var['Spliced']==0].copy()\n",
    "      print('unspliced')\n",
    "    else:\n",
    "      adata_in = adata.copy()\n",
    "\n",
    "    print(adata_in.X.shape)\n",
    "    scvi.data.setup_anndata(adata_in, layer=\"counts\")\n",
    "\n",
    "    \n",
    "    train_adata, test_adata = adata_in[train_index], adata_in[test_index]\n",
    "    train_adata = train_adata.copy()\n",
    "\n",
    "    ## Set model parameters\n",
    "    model_args = {'use_cuda'     : True,\n",
    "                  'n_latent'     : n_latent,\n",
    "                  'n_layers'     : n_layers,\n",
    "                  'dispersion'   : 'gene',\n",
    "                  'n_hidden'     : n_hidden,\n",
    "                  'dropout_rate' :  0.1,\n",
    "                  'gene_likelihood'    :  'nb',\n",
    "                  'log_variational'    :  True,\n",
    "                  'latent_distribution':  'normal',\n",
    "                  }\n",
    "    #model_args.update(additional_kwargs)\n",
    "\n",
    "    ## Create model\n",
    "    if method == 'NBcorr':\n",
    "        model = scBIVI.scBIVI(train_adata,mode='corr',**model_args)\n",
    "    elif method == 'NBuncorr':\n",
    "        model = scBIVI.scBIVI(train_adata,mode='uncorr',**model_args)\n",
    "    elif method == 'Poisson':\n",
    "        custom_dist = lambda x,mu1,mu2,theta,eps : custom_distributions.log_prob_poisson(x,mu1,mu2,theta,eps,THETA_IS = constant)\n",
    "        model = scBIVI.scBIVI(train_adata,mode='custom',custom_dist=custom_dist,**model_args)\n",
    "    elif method == 'nnNB':\n",
    "        custom_dist = lambda x,mu1,mu2,theta,eps : nnNB_module.log_prob_nnNB(x,mu1,mu2,theta,eps,THETA_IS = constant,\n",
    "                                                                             model= nnNB_module.model.to(torch.device('cuda')),\n",
    "                                                                             norm = NORM)\n",
    "        model = scBIVI.scBIVI(train_adata,mode='custom',custom_dist=custom_dist,**model_args)\n",
    "    elif method == 'vanilla.U':\n",
    "      model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.S':\n",
    "      model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.full':\n",
    "      model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.U.P':\n",
    "      model_args['gene_likelihood'] = 'poisson'\n",
    "      model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.S.P':\n",
    "      model_args['gene_likelihood'] = 'poisson'\n",
    "      model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.full.P':\n",
    "      model_args['gene_likelihood'] = 'poisson'\n",
    "      model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    else:\n",
    "        raise Exception('Input valid scVI model')\n",
    "\n",
    "    ## Train model\n",
    "    start = time.time()\n",
    "    model.train(n_epochs = n_epochs,\n",
    "                lr       = lr,\n",
    "                n_epochs_kl_warmup = n_epochs/2,\n",
    "                metrics_to_monitor = ['reconstruction_error'],\n",
    "                frequency = 1,\n",
    "                train_size = 0.9)\n",
    "\n",
    "    runtime     = time.time() - start\n",
    "    memory_used = torch.cuda.memory_allocated()\n",
    "    results_dict[setup]['runtime'].append(runtime)\n",
    "\n",
    "    ## Save training history\n",
    "    df_history = {'reconstruction_error_test_set' : model.history['reconstruction_error_test_set'],\n",
    "                  'reconstruction_error_train_set': model.history['reconstruction_error_train_set']}\n",
    "    df_history = pd.DataFrame(df_history)\n",
    "    df_history = pd.DataFrame(df_history.stack())\n",
    "    df = df_history\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['Epoch','Loss Type', 'Loss']\n",
    "    results_dict[setup]['df_history'] = df\n",
    "\n",
    "    ## Get reconstruction loss on test data\n",
    "    test_error  = model.get_reconstruction_error(test_adata)\n",
    "    train_error = model.get_reconstruction_error(train_adata)\n",
    "    results_dict[setup]['recon_error'].append(np.array([train_error,test_error]))\n",
    "\n",
    "\n",
    "    results_dict[setup]['params'] = model.get_likelihood_parameters(adata_in)\n",
    "\n",
    "    ## Extract the embedding space for scVI\n",
    "    X_out_full = model.get_latent_representation(adata_in)\n",
    "\n",
    "    adata.obsm[f'X_{method}'] = X_out_full\n",
    "    results_dict[setup][f'X_{n_latent}'] = X_out_full\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "  \n",
    "  return(results_dict,adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spZ0k7hG918d"
   },
   "source": [
    "# Compare Distributions\n",
    "\n",
    "\n",
    "Can change various training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AvsaCvPX98Ec"
   },
   "outputs": [],
   "source": [
    "#seed should not matter, but this seed works well\n",
    "# scvi._settings.ScviConfig.seed=(8675309)\n",
    "# torch.manual_seed(8675309)\n",
    "# # np.seed(8675309)\n",
    "# np.random.seed(8675309)\n",
    "\n",
    "# Hyper-parameters\n",
    "hyperparameters = { 'lr'       : 1e-3,\n",
    "        'n_epochs' : 100, \n",
    "        'n_hidden' : 128,\n",
    "        'n_layers' : 3 }\n",
    "\n",
    "z  = 10\n",
    "constant = 'NAS_SHAPE'\n",
    "\n",
    "setups = [\n",
    "          f'vanilla.U-{z}-{constant}',\n",
    "          f'vanilla.S-{z}-{constant}',\n",
    "          f'vanilla.full-{z}-{constant}',\n",
    "          f'vanilla.U.P-{z}-{constant}',\n",
    "          f'vanilla.S.P-{z}-{constant}',\n",
    "          f'vanilla.full.P-{z}-{constant}',\n",
    "          f'Poisson-{z}-{constant}',\n",
    "          f'NBcorr-{z}-{constant}',\n",
    "          f'nnNB-{z}-{constant}'\n",
    "          ]\n",
    "\n",
    "metrics_list = [f'X_{z}','runtime','df_history','params','recon_error']\n",
    "results_dict = {setup:{metrics: [] for metrics in metrics_list} for setup in setups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiv2Tvnh-I2k",
    "outputId": "87f0b79d-b582-4f9b-b866-27d9d83b95e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla.U-10-NAS_SHAPE\n",
      "unspliced\n",
      "(8424, 2000)\n",
      "\u001b[34mINFO    \u001b[0m No batch_key inputted, assuming all cells are same batch                                                  \n",
      "\u001b[34mINFO    \u001b[0m No label_key inputted, assuming all cells have same label                                                 \n",
      "\u001b[34mINFO    \u001b[0m Using data from adata.layers\u001b[1m[\u001b[0m\u001b[32m\"counts\"\u001b[0m\u001b[1m]\u001b[0m                                                                    \n",
      "\u001b[34mINFO    \u001b[0m Computing library size prior per batch                                                                    \n",
      "\u001b[34mINFO    \u001b[0m Successfully registered anndata object containing \u001b[1;36m8424\u001b[0m cells, \u001b[1;36m2000\u001b[0m vars, \u001b[1;36m1\u001b[0m batches, \u001b[1;36m1\u001b[0m labels, and \u001b[1;36m0\u001b[0m       \n",
      "         proteins. Also registered \u001b[1;36m0\u001b[0m extra categorical covariates and \u001b[1;36m0\u001b[0m extra continuous covariates.               \n",
      "\u001b[34mINFO    \u001b[0m Please do not further modify adata until model is trained.                                                \n",
      "\u001b[34mINFO    \u001b[0m Training for \u001b[1;36m100\u001b[0m epochs                                                                                   \n",
      "\u001b[34mINFO    \u001b[0m KL warmup for \u001b[1;36m50.0\u001b[0m epochs                                                                                 \n",
      "Training...:   7%|â–‹         | 7/100 [00:15<03:26,  2.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f33421769256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_setups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cell Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cell Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-37130e494edc>\u001b[0m in \u001b[0;36mcompare_setups\u001b[0;34m(adata, setups, results_dict, hyperparameters, train_index, test_index)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m## Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     model.train(n_epochs = n_epochs,\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mlr\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mn_epochs_kl_warmup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/models/vaemixin.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, train_size, test_size, lr, n_epochs_kl_warmup, n_iter_kl_warmup, frequency, train_fun_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training for {} epochs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_fun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_trained_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, lr, eps, params, **extras_kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iteration_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# Update the model's parameters after seeing the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Checks the training status, ensures no nan loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iteration_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/trainers/trainer.py\u001b[0m in \u001b[0;36mon_training_loop\u001b[0;34m(self, tensors_dict)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/trainers/inference.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, tensors, feed_labels)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeed_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         reconst_loss, kl_divergence_local, kl_divergence_global = self.model(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0msample_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_l_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_l_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/modules/vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, local_l_mean, local_l_var, batch_index, y)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \"\"\"\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# Parameters for z latent distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0mqz_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qz_m\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mqz_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qz_v\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/modules/vae.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, x, batch_index, y, n_samples, transform_batch)\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mdec_batch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         px_scale, px_r, px_rate, px_dropout = self.decoder(\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispersion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_batch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/modules/_base/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dispersion, z, library, *cat_list)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# The decoder returns values for the parameters of the ZINB distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcat_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mpx_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx_scale_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mpx_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx_dropout_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scvi/core/modules/_base/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *cat_list)\u001b[0m\n\u001b[1;32m    193\u001b[0m                                 \u001b[0mone_hot_cat_list_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_cat_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mone_hot_cat_list_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/traceback.py\u001b[0m in \u001b[0;36mline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[0;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_dict, adata = compare_setups(adata, setups,results_dict,hyperparameters)\n",
    "results_dict['Cell Type'] = adata.obs['Cell Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSfIMlvXHZlr"
   },
   "source": [
    "# Save results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFCx90x8LNOV"
   },
   "outputs": [],
   "source": [
    "results_file = open(f\"../results/{name}_results_dict.pickle\", \"wb\")\n",
    "pickle.dump(results_dict, results_file)\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2gBcem9JF30"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
