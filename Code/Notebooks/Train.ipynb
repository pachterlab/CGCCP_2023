{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LyHDS0r64Po"
   },
   "source": [
    "# Train Models on Various Datasets\n",
    "\n",
    "This notebook contains functions to train models and stores results needed for analysis. \n",
    "\n",
    "\n",
    "It compares models: \n",
    "\n",
    "1. Bursty model of transcription (nnNB), full data\n",
    "2. Constitutive model of transcription (Poisson), full data\n",
    "3. Bivariate negative binomial model (BVNB or Extrinsic model), full data\n",
    "4. \"vanilla scVI\" (negative binomial likelihoods), full data data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It outputs and stores a results dictionary that contains for each of the setups:\n",
    "\n",
    "1. X_10: latent space with dimension 10\n",
    "2. reconstructed parameters: means and dispersions\n",
    "3. normalized/unscaled reconstructed means\n",
    "3. reconstruction loss over training epochs train/test\n",
    "5. final reconstruction loss on test/train data\n",
    "4. runtime\n",
    "\n",
    "\n",
    "Analysis functions are not included in this training notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16772,
     "status": "ok",
     "timestamp": 1665091829735,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "Dx9K8ecWF2FN",
    "outputId": "18397fb0-b943-41f0-c994-0641d6239ddc"
   },
   "outputs": [],
   "source": [
    "# # mount drive \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd drive/MyDrive/grad/scBIVI/GCCCP_2021/Code/Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rOMjTFRNFv0S"
   },
   "outputs": [],
   "source": [
    "# clone the repo -- private right now -- if necessary\n",
    "#!git clone https://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@github.com/pachterlab/GCCCP_2021.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NjOTtMjv63GY"
   },
   "outputs": [],
   "source": [
    "# install necessary pacakges\n",
    "# %%capture\n",
    "# !pip install scanpy -q\n",
    "# !pip install scvi-tools==0.18.0 -q\n",
    "# !pip install loompy -q\n",
    "# !pip install leidenalg -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2099,
     "status": "ok",
     "timestamp": 1665091861095,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "YTE6OfMK9PKZ",
    "outputId": "ca8f59f3-0be8-44c7-a945-5324e710cc82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tara/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1f9ed86e20d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination"
     ]
    }
   ],
   "source": [
    "# check GPU availability\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "memory_used = torch.cuda.memory_allocated()\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9pkgIX6swDe9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/tara/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/home/tara/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "import time, gc\n",
    "\n",
    "# add module paths to sys path\n",
    "import sys\n",
    "sys.path.insert(0, '../BIVI/')\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# to save results\n",
    "import pickle\n",
    "\n",
    "# scvi\n",
    "import anndata\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7682,
     "status": "ok",
     "timestamp": 1665091873071,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "JsCFILc9CiWj",
    "outputId": "e1aa28f3-630a-43b2-cbeb-df3a5b426388"
   },
   "outputs": [],
   "source": [
    "# import biVI scripts\n",
    "import biVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0lQ5lR7XUHd"
   },
   "source": [
    "# Load in data \n",
    "\n",
    "\n",
    "Change data name to test out different simulated datasets with varying number of celltypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6004,
     "status": "ok",
     "timestamp": 1665091879064,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "SHnXm3Pq6WCU",
    "outputId": "be89c4f1-9aba-4fe8-d077-edfa211a07ca"
   },
   "outputs": [],
   "source": [
    "name = 'bursty_5ct'\n",
    "\n",
    "# change to hdf5 file if that is what you store data as\n",
    "adata = anndata.read_loom(f'../../data/simulated_data/{name}.loom')\n",
    "\n",
    "if 'gene_name' in adata.var.columns:\n",
    "    adata.var_names = adata.var['gene_name'].to_list()\n",
    "\n",
    "# can change as necessary for data. \n",
    "adata.obs['Cluster'] = adata.obs['Cell Type']\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxjYlTsdc9vO"
   },
   "outputs": [],
   "source": [
    "#Set up train/test data splits with 5-fold split\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "skf_splits = skf.split(adata, adata.obs['Cluster'])\n",
    "\n",
    "# Use last of the K-fold splits\n",
    "for k, (train_index, test_index) in enumerate(skf_splits):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1665091879066,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "0tRntI7mxGXc",
    "outputId": "70415db8-f784-4d08-96bb-870a6c9a674c"
   },
   "outputs": [],
   "source": [
    "print(f'training on {len(train_index)} cells, testing on {len(test_index)} cells')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuWAkvshCjua"
   },
   "source": [
    "-----\n",
    "\n",
    "\n",
    "# Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoSUe5ih2f0F"
   },
   "outputs": [],
   "source": [
    "# if anything goes wrong in training, this will catch where it happens\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# compare setups\n",
    "def compare_setups(adata, setups, results_dict, hyperparameters, train_index = train_index, test_index = test_index):\n",
    "  ''' Runs scBIVI on adata for listed setups in setups given hyperparameters, stores outputs in results_dict. \n",
    "      Train index and test index are defined globally -- could be nice to pass these in as well? \n",
    "  ''' \n",
    "\n",
    "  lr = hyperparameters['lr']\n",
    "  max_epochs = hyperparameters['max_epochs']\n",
    "  n_hidden = hyperparameters['n_hidden']\n",
    "  n_layers = hyperparameters['n_layers']\n",
    "\n",
    "  \n",
    "  for setup in setups:\n",
    "    print(setup)\n",
    "    method,n_latent,constant, = setup.split(\"-\")\n",
    "    n_latent = int(n_latent)\n",
    "\n",
    "    # test using only spliced or unspliced in vanilla scVI\n",
    "    if '.S' in method:\n",
    "      adata_in = adata[:,adata.var['Spliced']==1]\n",
    "      print('spliced')\n",
    "    elif '.U' in method:\n",
    "      adata_in = adata[:,adata.var['Spliced']==0]\n",
    "      print('unspliced')\n",
    "    else:\n",
    "      adata_in = adata.copy()\n",
    "    print(adata_in.X.shape)\n",
    "    #biVI.biVI.setup_anndata(adata_in,layer=\"counts\")\n",
    "    #categorical_covariate_keys=[\"cell_source\", \"donor\"],\n",
    "    #continuous_covariate_keys=[\"percent_mito\", \"percent_ribo\"])\n",
    "\n",
    "    \n",
    "    train_adata, test_adata = adata_in[train_index], adata_in[test_index]\n",
    "    train_adata = train_adata.copy()\n",
    "    test_adata = test_adata.copy()\n",
    "    if 'vanilla' in method:\n",
    "        scvi.model.SCVI.setup_anndata(test_adata,layer=\"counts\")\n",
    "        scvi.model.SCVI.setup_anndata(train_adata,layer=\"counts\")\n",
    "    else:\n",
    "        biVI.biVI.setup_anndata(test_adata,layer=\"counts\")\n",
    "        biVI.biVI.setup_anndata(train_adata,layer=\"counts\")\n",
    "    \n",
    "\n",
    "    ## Set model parameters\n",
    "    model_args = {\n",
    "                  'n_latent'     : n_latent,\n",
    "                  'n_layers'     : n_layers,\n",
    "                  'dispersion'   : 'gene',\n",
    "                  'n_hidden'     : n_hidden,\n",
    "                  'dropout_rate' :  0.1,\n",
    "                  'gene_likelihood'    :  'nb',\n",
    "                  'log_variational'    :  True,\n",
    "                  'latent_distribution':  'normal',\n",
    "                  }\n",
    "    #model_args.update(additional_kwargs)\n",
    "\n",
    "    ## Create model\n",
    "    if method == 'NBcorr':\n",
    "        model = biVI.biVI(train_adata,mode='NBcorr',**model_args)\n",
    "    elif method == 'NBuncorr':\n",
    "        model = biVI.biVI(train_adata,mode='NBuncorr',**model_args)\n",
    "    elif method == 'Poisson':\n",
    "        model = biVI.biVI(train_adata,mode='Poisson',**model_args)\n",
    "    elif method == 'Bursty':\n",
    "        model = biVI.biVI(train_adata,mode='Bursty',**model_args)\n",
    "    elif method == 'vanilla.U':\n",
    "        model_args['gene_likelihood'] = 'nb'\n",
    "        model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.S':\n",
    "        model_args['gene_likelihood'] = 'nb'\n",
    "        model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.full':\n",
    "        model_args['gene_likelihood'] = 'nb'\n",
    "        model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.U.P':\n",
    "        model_args['gene_likelihood'] = 'poisson'\n",
    "        model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.S.P':\n",
    "        model_args['gene_likelihood'] = 'poisson'\n",
    "        model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    elif method == 'vanilla.full.P':\n",
    "        model_args['gene_likelihood'] = 'poisson'\n",
    "        model = scvi.model.SCVI(train_adata,**model_args)\n",
    "    else:\n",
    "        raise Exception('Input valid scVI model')\n",
    "\n",
    "    ## Train model\n",
    "    plan_kwargs = {'lr' : lr,\n",
    "                   'n_epochs_kl_warmup' : max_epochs/2,\n",
    "                   }\n",
    "    \n",
    "    start = time.time()\n",
    "    model.train(max_epochs = max_epochs,\n",
    "                #early_stopping_monitor = [\"reconstruction_loss_validation\"],\n",
    "                train_size = 0.9,\n",
    "                check_val_every_n_epoch  = 1,\n",
    "                plan_kwargs = plan_kwargs)\n",
    "\n",
    "    \n",
    "    runtime     = time.time() - start\n",
    "    memory_used = torch.cuda.memory_allocated()\n",
    "    results_dict[setup]['runtime'].append(runtime)\n",
    "\n",
    "    ## Save training history\n",
    "    df_history = {'reconstruction_error_test_set' : [model.history['reconstruction_loss_train']],\n",
    "                  'reconstruction_error_train_set': [model.history['reconstruction_loss_validation']]}\n",
    "    df_history = pd.DataFrame(df_history,index=[0])\n",
    "    df_history = pd.DataFrame(df_history.stack())\n",
    "    df = df_history\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['Epoch','Loss Type', 'Loss']\n",
    "    results_dict[setup]['df_history'] = df\n",
    "\n",
    "    ## Get reconstruction loss on test data\n",
    "    test_error  = model.get_reconstruction_error(test_adata)\n",
    "    train_error = model.get_reconstruction_error(train_adata)\n",
    "    results_dict[setup]['recon_error'].append(np.array([train_error,test_error]))\n",
    "\n",
    "\n",
    "    results_dict[setup]['params'] = model.get_likelihood_parameters(adata)\n",
    "\n",
    "    ## Extract the embedding space for scVI\n",
    "    X_out_full = model.get_latent_representation(adata_in)\n",
    "\n",
    "    adata.obsm[f'X_{method}'] = X_out_full\n",
    "    results_dict[setup][f'X_{n_latent}'] = X_out_full\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "  \n",
    "  return(results_dict,adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spZ0k7hG918d"
   },
   "source": [
    "# Compare Distributions\n",
    "\n",
    "\n",
    "Can change various training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvsaCvPX98Ec"
   },
   "outputs": [],
   "source": [
    "#seed should not matter, but this seed works well\n",
    "# scvi._settings.ScviConfig.seed=(8675309)\n",
    "# torch.manual_seed(8675309)\n",
    "# # np.seed(8675309)\n",
    "# np.random.seed(8675309)\n",
    "\n",
    "# Hyper-parameters\n",
    "hyperparameters = { 'lr'       : 1e-3,\n",
    "        'max_epochs' : 100, \n",
    "        'n_hidden' : 128,\n",
    "        'n_layers' : 3 }\n",
    "\n",
    "z  = 10\n",
    "constant = 'NAS_SHAPE'\n",
    "\n",
    "setups = [\n",
    "#           f'vanilla.U-{z}-{constant}',\n",
    "#           f'vanilla.S-{z}-{constant}',\n",
    "#           f'vanilla.full-{z}-{constant}',\n",
    "#           f'vanilla.U.P-{z}-{constant}',\n",
    "#           f'vanilla.S.P-{z}-{constant}',\n",
    "#           f'vanilla.full.P-{z}-{constant}',\n",
    "          f'Poisson-{z}-{constant}',\n",
    "          f'NBcorr-{z}-{constant}',\n",
    "          #f'Bursty-{z}-{constant}'\n",
    "          ]\n",
    "\n",
    "metrics_list = [f'X_{z}','runtime','df_history','params','recon_error']\n",
    "results_dict = {setup:{metrics: [] for metrics in metrics_list} for setup in setups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiv2Tvnh-I2k",
    "outputId": "87f0b79d-b582-4f9b-b866-27d9d83b95e6"
   },
   "outputs": [],
   "source": [
    "results_dict, adata = compare_setups(adata, setups,results_dict,hyperparameters)\n",
    "results_dict['Cell Type'] = adata.obs['Cell Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['Poisson-10-NAS_SHAPE']['params']['mean'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSfIMlvXHZlr"
   },
   "source": [
    "# Save results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFCx90x8LNOV"
   },
   "outputs": [],
   "source": [
    "results_file = open(f\"../../results/{name}_results_dict.pickle\", \"wb\")\n",
    "pickle.dump(results_dict, results_file)\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
