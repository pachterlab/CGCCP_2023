{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pachterlab/GCCCP_2021/blob/main/Code/Notebooks/Simulate_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LyHDS0r64Po"
   },
   "source": [
    "# Simulate scRNA-seq count data\n",
    "\n",
    "This notebook generates simulated count data for three realistic models of transcription: \"constitutive\" transcription which results in Poisson distributed single cell RNA counts for spliced and unspliced species, \"bursy\" transcription, which results in a distribution of spliced and unspliced RNA with no closed form solution, and another form of constitution transcription (with gamma distributed transcription initiation rates) that results in correlated negative binomially distributed data.\n",
    "\n",
    "1. Bursty\n",
    "2. Constitutive\n",
    "3. BVNB\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27988,
     "status": "ok",
     "timestamp": 1663796369387,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "QbqmdAOxbv2b",
    "outputId": "c45a7738-f776-4d54-cf29-0ca67e8c72be"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd drive/MyDrive/grad/scBIVI/GCCCP_2021/Code/Notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1663796369388,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "5TdtMiO7Lzvm"
   },
   "outputs": [],
   "source": [
    "# clone the repo -- private right now\n",
    "# !git clone https://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@github.com/pachterlab/GCCCP_2021.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 25377,
     "status": "ok",
     "timestamp": 1663796394759,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "SKxVKZVae6gz"
   },
   "outputs": [],
   "source": [
    "# System\n",
    "import os, time\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "#%%capture\n",
    "!pip install anndata scanpy==1.7.2 -q\n",
    "!pip install loompy -q\n",
    "!pip install leidenalg -q\n",
    "# # !pip uninstall torch --yes \n",
    "# !pip install --upgrade torch torchvision\n",
    "#!pip install --upgrade torch==1.12.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2222,
     "status": "ok",
     "timestamp": 1663796396972,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "RllirPXDvA0m"
   },
   "outputs": [],
   "source": [
    "# sc Processing\n",
    "import anndata\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "executionInfo": {
     "elapsed": 1787,
     "status": "ok",
     "timestamp": 1663796398754,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "9pkgIX6swDe9",
    "outputId": "a83b927d-b70f-4919-f99d-4e18be152081"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 432x288 with 1 Axes>, <AxesSubplot:>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System\n",
    "import os, time\n",
    "\n",
    "\n",
    "# change to working directory\n",
    "# os.chdir(\"/content/GCCCP_2021/Code/Notebooks\")\n",
    "\n",
    "# add directories with necessary modules to system path\n",
    "import sys\n",
    "sys.path.insert(0,'../custom_distributions/')\n",
    "sys.path.insert(0, '../analysis_scripts/')\n",
    "sys.path.insert(0, '../BIVAE/')\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "import torch\n",
    "import gc\n",
    "import scipy\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "# Plots\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6004,
     "status": "ok",
     "timestamp": 1663796404755,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "aDkel2eaPXND",
    "outputId": "5fbbaad5-64ee-4daa-dddf-49ec9a48634d"
   },
   "outputs": [],
   "source": [
    "# neural network for bursty transcription module\n",
    "import nnNB_module\n",
    "# set the model to be on cuda for google colab\n",
    "nnNB_module.model.to(torch.device('cuda'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu113'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device to be cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMklY4401inN"
   },
   "source": [
    "# Generate parameters\n",
    "\n",
    "\n",
    "Parameters for cell type will be stored in numpy arrays of shape ( cell_type, gene, parameter): ( N_ct, N_g, 3) for bursty transcription and BVNB, and (N_ct, N_g, 2) for constitutive transcription.\n",
    "\n",
    "\n",
    "N_ct is the number of cell types, N_g is the number of genes, and 2 and 3 are the number of parameters in bursty and constitutive models of transcription respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1663796404756,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "vs0LNmqAiELG"
   },
   "outputs": [],
   "source": [
    "# # LOG10 of mean and LOG10 of std dev\n",
    "# mu_b = 0.2\n",
    "# mu_beta = 0.5\n",
    "# mu_gamma = 0.4\n",
    "\n",
    "# std_b =  0.6\n",
    "# std_beta = 0.3\n",
    "# std_gamma = 0.5\n",
    "\n",
    "\n",
    "# PARAMETERS FOR BVNB MODEL\n",
    "mu_BVNB = [2.53088,0.305065,0.2496]\n",
    "cov_BVNB = [[ 1.01194454, 0.26126121, -0.08104601],\n",
    "            [ 0.26126121, 0.49394190,  0.10664739],\n",
    "            [-0.08104601, 0.10664739,  0.20601299]]\n",
    "\n",
    "# generate genes\n",
    "def generate_gene_parameters(N_ct, N_g, \n",
    "                                    mu_array =  [0.2,0.5,0.4],\n",
    "                                    std_array = [0.6,0.3,0.5],\n",
    "                                    cov_array = np.zeros((3,3)),\n",
    "                                    correlation_coeff = 0.8,\n",
    "                                    N_mg = 25,\n",
    "                                    std_eps = 0.05,\n",
    "                                    model = 'bursty'):\n",
    "  ''' Generates the log of gene parameters for a given number of cell types N_ct for a given number of genes N_g. Assumes a bursty model of transcription. \n",
    "\n",
    "  Parameters\n",
    "  ------\n",
    "  N_ct : number of cell types\n",
    "  N_g : number of genes\n",
    "\n",
    "\n",
    "  Optional\n",
    "  ------\n",
    "  mu_array : array of means for b, beta, gamma\n",
    "  std_array : array of standard deviation for b, beta, gamma\n",
    "  cov_array : array of covariances for alpha, log10(beta/theta), log10(gamma/theta), optional but REQUIRED FOR BVNB MODEL\n",
    "  correlation_coeff : correlation scaling to generate parameters for each gene from a correlated multivariate normal dist.\n",
    "  N_mg : average number of marker genes per cell type (average of a Poisson distribution)\n",
    "  std_eps : standard deviation for normally distributed random variable used to add noise to housekeeper gene parameter\n",
    "  model : string, options ['bursty','const','BVNB'], default 'bursty'\n",
    "\n",
    "\n",
    "  Returns\n",
    "  ------\n",
    "  param_array = array of size (N_ct, N_g, 3/2/4) for bursty/const/NBuncorr models \n",
    "  '''\n",
    "\n",
    "  mu_array = np.array(mu_array)\n",
    "  std_array = np.array(std_array)\n",
    "  cov_array = np.array(cov_array)\n",
    "\n",
    "  if model == 'const':\n",
    "    # setup covariance matrix\n",
    "    N_params = 2\n",
    "    if len(mu_array) == 3:\n",
    "      mu_array = mu_array[1:]\n",
    "      std_array = std_array[1:]\n",
    "    cov_array = np.zeros((N_params,N_params))\n",
    "    for i in range(N_params):\n",
    "      for j in range(N_params):\n",
    "        rho = correlation_coeff\n",
    "        if i == j :\n",
    "          rho = 1\n",
    "        cov_ij = std_array[i]*std_array[j]*rho\n",
    "        cov_array[i,j] = cov_ij\n",
    "\n",
    "  if model == 'bursty':\n",
    "    # setup covariance matrix\n",
    "    N_params = 3\n",
    "    cov_array = np.zeros((N_params,N_params))\n",
    "    for i in range(N_params):\n",
    "      for j in range(N_params):\n",
    "        rho = correlation_coeff\n",
    "        if i == j :\n",
    "          rho = 1\n",
    "        cov_ij = std_array[i]*std_array[j]*rho\n",
    "        cov_array[i,j] = cov_ij\n",
    "\n",
    "  if model == 'BVNB':\n",
    "    N_params = 3\n",
    "    mu_array = np.copy(mu_BVNB)\n",
    "    cov_array = np.copy(cov_BVNB)\n",
    "\n",
    "    # covariance array already input\n",
    "\n",
    "  # set up array to store parameters\n",
    "  param_array = np.zeros((N_ct,N_g,N_params))\n",
    "\n",
    "\n",
    "  # generate housekeeping genes from multivariate normal distribution\n",
    "  baseline_params = np.random.multivariate_normal(mean = mu_array, cov = cov_array, size = N_g)\n",
    "\n",
    "\n",
    "  for ct in range(N_ct):\n",
    "    param_array[ct,:,:] = baseline_params \n",
    "  \n",
    "  # add some random noise to housekeeping genes except to what is constant\n",
    "  if model =='const':\n",
    "    param_array = param_array[ct,:,:] + np.random.normal(loc = 0, scale = std_eps, size = (N_ct,N_g,N_params))\n",
    "  elif model =='bursty':\n",
    "    # add noise to b\n",
    "    param_array = param_array[ct,:,0] + np.random.normal(loc = 0, scale = std_eps, size = (N_ct,N_g,1))\n",
    "    # add noise to gamma\n",
    "    param_array = param_array[ct,:,2] + np.random.normal(loc = 0, scale = std_eps, size = (N_ct,N_g,1))\n",
    "  else:\n",
    "    min_alpha = 0.1\n",
    "    param_array[:,:,0][param_array[:,:,0]<min_alpha] = min_alpha\n",
    "    param_array[:,:,1:] = param_array[:,:,1:] + np.random.normal(loc = 0, scale = std_eps, size = (N_ct,N_g,N_params-1))\n",
    "\n",
    "  # MARKER genes YAHOO\n",
    "  possible_marker_genes = np.arange(N_g)\n",
    "  mg_probs = np.ones(N_g)\n",
    "  mg_probs /= mg_probs.sum()\n",
    "\n",
    "  marker_annotations = np.asarray([-1]*N_g,dtype=int)\n",
    "  # possible_marker_genes = list(range(N_g))\n",
    "  num_mg = []\n",
    "\n",
    "  for ct in range(N_ct):\n",
    "    # choose number of marker genes from Poisson distribution with default average of 25\n",
    "    num_mg_ = np.random.poisson(lam = N_mg) + 2\n",
    "    num_mg.append(num_mg_)\n",
    "\n",
    "    # select which genes they are randomly \n",
    "    mg_index = np.random.choice(possible_marker_genes,num_mg_,replace=False,p=mg_probs)\n",
    "    #np.array(random.sample(possible_marker_genes,num_mg_))\n",
    "\n",
    "    # remove the marker genes so that there are no overlapping MGs\n",
    "    mg_probs[mg_index] = 0\n",
    "    mg_probs /= mg_probs.sum()\n",
    "    # possible_marker_genes = [mg for mg in possible_marker_genes if mg not in mg_index]\n",
    "\n",
    "    #store annotations\n",
    "    marker_annotations[mg_index] = ct\n",
    "\n",
    "\n",
    "    if model == 'const':\n",
    "      # does k, transcriptional initiation rate, or gamma, degradation, change? \n",
    "      a = np.random.rand(num_mg_)\n",
    "      # a = np.random.uniform(0,1,size = num_mg_)\n",
    "      mg_k_increase = mg_index[a > 0]\n",
    "      # mg_gamma_decrease = mg_index[a < 0.45]\n",
    "\n",
    "      # modulate marker gene expression\n",
    "      param_array[ct,mg_k_increase,:] = param_array[ct,mg_k_increase,:] - np.random.normal(loc=1.2, scale = 0.1, size = len(mg_k_increase))[:,None]\n",
    "      # param_array[ct,mg_gamma_decrease,1] = param_array[ct,mg_gamma_decrease,1] - np.random.normal(loc=1.2, scale = 0.1, size = len(mg_gamma_decrease) )\n",
    "      \n",
    "    if model == 'bursty': \n",
    "      # does k, transcriptional initiation rate, or b, burst size, change? \n",
    "      a = np.random.uniform(0,1,size = num_mg_)\n",
    "      # mg_k_increase = mg_index[a > 1.0]\n",
    "      mg_b_increase = mg_index[a < 1.0]\n",
    "\n",
    "      # modulate marker gene expression\n",
    "      # param_array[ct,mg_k_increase,-2:] = param_array[ct,mg_k_increase,-2:] - np.random.normal(loc=1.2, scale = 0.1, size = len(mg_k_increase))[:,None]\n",
    "      param_array[ct,mg_b_increase,0] = param_array[ct,mg_b_increase,0] + np.random.normal(loc=1.2, scale = 0.1, size = len(mg_b_increase))\n",
    "\n",
    "    if model == 'BVNB':\n",
    "      # does alpha, the shape parameter for gamma distribution modulating transcriptional initiation rate k increase, or beta decrease\n",
    "      a = np.random.uniform(0,1,size = num_mg_)\n",
    "      # mg_alpha_increase = mg_index[a > 1]\n",
    "      mg_k_increase = mg_index[a<1]\n",
    "      # mg_gamma_decrease = mg_index[a < 0.45]\n",
    "\n",
    "      # modulate marker gene expression\n",
    "      # param_array[ct,mg_alpha_increase,0] = param_array[ct,mg_alpha_increase,0] + np.random.normal(loc=2.0, scale = .5, size = len(mg_alpha_increase))\n",
    "      param_array[ct,mg_k_increase,1:] = param_array[ct,mg_k_increase,1:] - np.random.normal(loc=1.2, scale = 0.1, size = len(mg_k_increase))[:,None]\n",
    "      # param_array[ct,mg_gamma_decrease,2] = param_array[ct,mg_gamma_decrease,-1] - np.random.normal(loc=1.2, scale = 0.1, size = len(mg_gamma_decrease))\n",
    "\n",
    "  num_mg = np.asarray(num_mg)\n",
    "\n",
    "  return param_array, marker_annotations, num_mg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfvZPUNJzI_N"
   },
   "source": [
    "Amazing! Generating gene parameters for bursty and Poisson model now works. Love that. \n",
    "\n",
    "\n",
    "Now to generate full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1663796404756,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "KN2G-HFlzion"
   },
   "outputs": [],
   "source": [
    "def generate_count_data(N_cells, N_ct, N_g, distribution, model = 'bursty', N_mg = 25):\n",
    "  ''' Generates count data matrix for N_cells, N_celltypes, given a distribution (bursty or constitutive).\n",
    "    (If I wanted to generate uncorrelated Negative Binomial data or bivariate Negative Binomial data, how would I get the means and std from the current method of parameter sampling?)\n",
    "  \n",
    "  Parameters \n",
    "  ------\n",
    "  N_cells : rough number of cells in the count matrix (will be slightly more because rounding up)\n",
    "  N_ct : number of cell types\n",
    "  N_genes : number of genes per cell\n",
    "  distribution : function that defines the distribution to sample from \n",
    "  model : 'bursty' or constitutive 'const' or 'BVNB' transcription \n",
    "\n",
    "\n",
    "  Returns\n",
    "  -----\n",
    "  count_matrix : matrix of size ( ~N_cells, N_genes, 2) where the third dimension is spliced, unspliced counts. \n",
    "  params : matrix of size (N_ct, N_genes, N_params) where N_params is 3 for bursty/BVNB and 2 for constitutive\n",
    "              --parameters for model per cell type per gene\n",
    "  cells_per_ct : int, number of cells per cell type\n",
    "  '''\n",
    "\n",
    "  # calculate the proportion of cells in each cell type -- dirichlet distribution\n",
    "  alpha = np.ones(N_ct)*4.0  # could change -- i think the higher the multiplied value, the more even the # cells per ct will be\n",
    "  ct_proportions = np.random.dirichlet(alpha)\n",
    "\n",
    "  # calculate the number of cells per cell type\n",
    "#   cells_per_ct = np.ceil(ct_proportions * N_cells)\n",
    "  cells_per_ct = np.random.multinomial(N_cells,ct_proportions)\n",
    "\n",
    "  # set up count matrix -- spliced and unspliced\n",
    "  count_matrix = np.zeros((int(np.sum(cells_per_ct)),N_g,2))\n",
    "\n",
    "  # generate log of parameters for all genes for each cell type\n",
    "  params,marker_annotations,num_mg = generate_gene_parameters(N_ct, N_g , N_mg = N_mg, model = model)\n",
    "\n",
    "  for i,ct in enumerate(range(N_ct)):\n",
    "    print('Cell type ',ct)\n",
    "    num_cells_ = cells_per_ct[i]\n",
    "    params_ = params[ct,:,:]\n",
    "    \n",
    "    # generates count matrix of size (num_cells_ , N_g, 2) given distribution and parameters of the distribution\n",
    "    if model == 'bursty':\n",
    "      count_data_ct = distribution(int(num_cells_) , params_) \n",
    "      count_matrix[int(np.sum(cells_per_ct[:i])):int(np.sum(cells_per_ct[:i+1])), :, :] = count_data_ct  #use range() or range(cumsum) for this\n",
    "      \n",
    "    else: \n",
    "      count_data_ct = distribution(int(num_cells_) , params_) \n",
    "      count_matrix[int(np.sum(cells_per_ct[:i])):int(np.sum(cells_per_ct[:i+1])), :, :] = count_data_ct \n",
    "\n",
    "  return count_matrix,params,cells_per_ct,marker_annotations,num_mg\n",
    "  # if model == 'bursty':\n",
    "  #   return(count_matrix,params,cells_per_ct)\n",
    "  # else:\n",
    "  #   return(count_matrix,params,cells_per_ct)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1663796404756,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "CprzqMli0PXt"
   },
   "outputs": [],
   "source": [
    "# sampling distributions\n",
    "\n",
    "def constitutive_transcription(num_cells, log_params):\n",
    "  ''' Produces a count matrix for num_cells_ given constitutive model of transcription and parameters. Spliced and unspliced.\n",
    "  Uncorrelated Poisson distribution.\n",
    "\n",
    "  Parameters\n",
    "  -----\n",
    "  num_cells : number of cells for which to generate counts\n",
    "  params : parameters for each gene for a constitutive model of transcription\n",
    "\n",
    "  Returns\n",
    "  ---\n",
    "  count_data : array of size (num_cells_, len(params), 2) with spliced and unspliced data\n",
    "  '''\n",
    "\n",
    "  params = 10**log_params\n",
    "  nascent_means = 1/params[:,0]\n",
    "  mature_means = 1/params[:,1]\n",
    "\n",
    "  nascent_counts = np.random.poisson(lam = nascent_means,size = (num_cells,len(params)))\n",
    "  mature_counts = np.random.poisson(lam = mature_means,size = (num_cells,len(params)))\n",
    "\n",
    "\n",
    "  count_data = np.zeros((num_cells,len(params),2))\n",
    "  count_data[:,:,0] = nascent_counts\n",
    "  count_data[:,:,1] = mature_counts\n",
    "\n",
    "  return(count_data)\n",
    "\n",
    "\n",
    "def BVNB(num_cells, params):\n",
    "  ''' \n",
    "\n",
    "  Produces a count matrix for num_cells_ given bivariate CORRELATED negative binomial distribution and parameters for that model. Spliced and unspliced.\n",
    "    \n",
    "  Parameters\n",
    "  -----\n",
    "  num_cells : number of cells for which to generate counts\n",
    "  params : parameters for each gene\n",
    "\n",
    "  Returns\n",
    "  ---\n",
    "  count_data : array of size (num_cells_, len(params), 2) with spliced and unspliced data\n",
    "  '''\n",
    "\n",
    "\n",
    "  alpha = params[:,0]\n",
    "  beta = 10**params[:,1]\n",
    "  gamma = 10**params[:,2]\n",
    "  N_g = len(params)\n",
    "\n",
    "  # parameters are (k, theta, beta, gamma)\n",
    "  # k is shape and theta is scale of gamma distribution\n",
    "  # sample K from gamma distribution \n",
    "\n",
    "  K = np.random.gamma(alpha, size = (num_cells,N_g))\n",
    "\n",
    "  nascent_counts = np.random.poisson(lam = K/beta[None,:])\n",
    "  mature_counts = np.random.poisson(lam = K/gamma[None,])\n",
    "\n",
    "  # print(nascent_counts.shape)\n",
    "  # print(mature_counts.shape)\n",
    "  # print(alpha[0])\n",
    "  # print(K[:,0].mean())\n",
    "  # print(beta[0])\n",
    "  # print(gamma[0])\n",
    "  # print(K[:,0].mean()/beta[0])\n",
    "  # raise ValueError\n",
    "\n",
    "  # nascent_counts = np.random.poisson(lam = K/beta, size = (num_cells,len(params)))\n",
    "  # mature_counts = np.random.poisson(lam = K/gamma, size = (num_cells,len(params)))\n",
    "\n",
    "\n",
    "  count_data = np.zeros((num_cells, len(params),2))\n",
    "  count_data[:,:,0] = nascent_counts\n",
    "  count_data[:,:,1] = mature_counts\n",
    "\n",
    "  return(count_data)\n",
    "\n",
    "\n",
    "def bursty_transcription(num_cells, log_params):\n",
    "  ''' Generates count data for a bursty model of transcription. Spliced and unspliced data.\n",
    "\n",
    "  Sampling works as follows:\n",
    "\n",
    "  1. Pull from nascent NB given moments of the CME solution to get nascent counts. \n",
    "  2. Run the parameter through the NN to return weights and hyperparameters. \n",
    "  3. Pull from a discrete distribution of kernel functions with probabilities given by NN weights. \n",
    "  4. Sample from the NB kernel function of the chosen kernel function to get mature counts. \n",
    "\n",
    "  Parameters\n",
    "  ------\n",
    "  num_cells : number of cells to generate count data for\n",
    "  log_params : parameters of genes for a bursty model of transcription (log of params)\n",
    "\n",
    "  Returns\n",
    "  ------\n",
    "  count_matrix : matrix of count data size (num_cells, N_g, 2)\n",
    "  '''\n",
    "  eps = 1e-8\n",
    "\n",
    "  params = 10**log_params\n",
    "  b,beta,gamma = params[:,0],params[:,1],params[:,2]\n",
    "\n",
    "\n",
    "  # calculate nascent marginal negative binomial P(n) \n",
    "  n_nascent = 1/beta\n",
    "  p_nascent = 1/(b+1)\n",
    "\n",
    "  nascent_counts = np.random.negative_binomial(n = n_nascent, p = p_nascent, size = (num_cells, len(params)))\n",
    "\n",
    "  # get weights with model\n",
    "  weights, n_10_mature, p_10_mature, mu_10_mature, logmean_cond, logvar_cond = get_NN_weights_NB_params(params, nascent_counts.flatten(), num_cells)\n",
    "\n",
    "  # set up empty count matrices \n",
    "  mature_counts = np.zeros(len(nascent_counts.flatten()))\n",
    "\n",
    "  cumsum_weights = np.cumsum(weights,axis=1)\n",
    "  cumsum_weights[:,-1] = 1.000\n",
    "  random_choice = np.random.uniform(size = weights.shape[0])\n",
    "  random_choice[random_choice== 1.0] == 0.9999\n",
    "  indices = [np.sum(cumsum_weights[i,:]<rc) for i,rc in enumerate(random_choice)]\n",
    "  n_mature = np.array([n_10_mature[i,indices[i]] for i in range(len(indices))])\n",
    "  p_mature = np.array([p_10_mature[i,indices[i]] for i in range(len(indices))])\n",
    "  mu_mature = np.array([mu_10_mature[i,indices[i]] for i in range(len(indices))])\n",
    "\n",
    "  index_nb = np.logical_and(p_mature > 1e-10, n_mature > 0)\n",
    "  index_poisson = ~index_nb\n",
    "  mature_counts[index_poisson] = np.random.poisson(lam = mu_mature[index_poisson])\n",
    "  mature_counts[index_nb] = np.random.negative_binomial(n = n_mature[index_nb], p = p_mature[index_nb])\n",
    "  mature_counts = mature_counts.reshape(nascent_counts.shape)\n",
    "\n",
    "  count_data = np.zeros((num_cells,len(params),2))\n",
    "  count_data[:,:,0] = nascent_counts\n",
    "  count_data[:,:,1] = mature_counts\n",
    "\n",
    "\n",
    "  return(count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1663796404756,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "i1LPx3ziyaTh"
   },
   "outputs": [],
   "source": [
    "def get_NN_weights_NB_params(params, nascent_values, num_cells):\n",
    "    ''' Get weights for bivariate lognormal given parameter values. \n",
    "\n",
    "    Parameters \n",
    "    ------\n",
    "    params: parameters of a bursty model of transcription (b,beta,gamma) NOT LOG -- IMPORTANT\n",
    "    nascent_values : nascent count values at which to evaluate\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    weights : weights for the NB distribution for each cell/gene \n",
    "    hyp : \n",
    "    '''\n",
    "    # empty torch cache?\n",
    "    \n",
    "    \n",
    "    b,beta,gamma = torch.tensor(params[:,0]).repeat(num_cells),torch.tensor(params[:,1]).repeat(num_cells),torch.tensor(params[:,2]).repeat(num_cells)\n",
    "    mu1,mu2 = b/beta, b/gamma\n",
    "\n",
    "    # get moments\n",
    "    var1 = mu1 * (1+b)\n",
    "    var2 = mu2 * (1+b*beta/(beta+gamma))\n",
    "    cov = b**2/(beta+gamma)\n",
    "\n",
    "    nascent_values = torch.tensor(nascent_values)\n",
    "\n",
    "    # calculate conditional moments\n",
    "    logvar1 = torch.log((var1/mu1**2)+1)\n",
    "    logvar2 = torch.log((var2/mu2**2)+1)\n",
    "    logstd1 = torch.sqrt(logvar1)\n",
    "    logstd2 = torch.sqrt(logvar2)\n",
    "\n",
    "    logmean1 = torch.log(mu1**2/torch.sqrt(var1+mu1**2))\n",
    "    logmean2 = torch.log(mu2**2/torch.sqrt(var2+mu2**2))\n",
    "\n",
    "    # val = (logmean1 + logmean2 + (logvar1 + logvar2)/2)\n",
    "    # val[val<-88] = -88\n",
    "\n",
    "    logcov = np.log(cov * np.exp(-(logmean1 + logmean2 + (logvar1+logvar2)/2) ) + 1 )\n",
    "    #logcov = torch.log(cov * torch.exp(-(val)) +1 )\n",
    "    logcorr = logcov/torch.sqrt(logvar1 * logvar2)\n",
    "\n",
    "    logmean_cond = logmean2 + logcorr * logstd2/logstd1 * (torch.log(nascent_values+1) - logmean1)\n",
    "    logvar_cond = logvar2 * (1-logcorr**2)  \n",
    "    logstd_cond = logstd2 * torch.sqrt(1-logcorr**2)  \n",
    "\n",
    "    xmax_m = torch.ceil(torch.ceil(mu2) + 4*torch.sqrt(var2))\n",
    "    xmax_m = torch.clip(xmax_m,30,np.inf).int()\n",
    "  \n",
    "\n",
    "    # reshape and stack\n",
    "    pv = torch.column_stack((torch.log10(b).reshape(-1),\n",
    "                             torch.log10(beta).reshape(-1),\n",
    "                             torch.log10(gamma).reshape(-1),\n",
    "                             logmean_cond.reshape(-1),\n",
    "                             logstd_cond.reshape(-1),\n",
    "                             xmax_m.reshape(-1),\n",
    "                             nascent_values.reshape(-1)\n",
    "                             ))\n",
    "    \n",
    "    pv = pv.to(torch.float)\n",
    "\n",
    "    split = 10000\n",
    "    num_model_runs = int(np.ceil(pv.shape[0]/split))\n",
    "    pv_ = pv[:split]\n",
    "    \n",
    "    w,hyp = nnNB_module.model(pv_.to(torch.device('cuda')))\n",
    "    w,hyp = w.cpu().detach(),hyp.cpu().detach()\n",
    "    \n",
    "    for index in range(num_model_runs):\n",
    "      \n",
    "      index_ = index+1\n",
    "      pv_ = pv[index_*split:(index_+1)*split]\n",
    "      w_cuda,hyp_cuda = nnNB_module.model(pv_.to(torch.device('cuda')))\n",
    "      w_,hyp_ = w_cuda.cpu().detach(),hyp_cuda.cpu().detach()\n",
    "      del w_cuda,hyp_cuda\n",
    "      torch.cuda.empty_cache()\n",
    "      gc.collect()\n",
    "      w, hyp = torch.concat((w,w_)), torch.concat((hyp,hyp_))\n",
    "\n",
    "    hyp = hyp*5+1\n",
    "\n",
    "    p_vec = 10**pv[:,0:3]\n",
    "    logmean_cond = pv[:,3]\n",
    "    logstd_cond = pv[:,4]\n",
    "        \n",
    "    grid = nnNB_module.generate_grid(logmean_cond,logstd_cond,nnNB_module.NORM)\n",
    "\n",
    "    s = torch.zeros((len(nascent_values),10))\n",
    "    s[:,:-1] = torch.diff(grid,axis=1)\n",
    "    s *= hyp\n",
    "    s[:,-1] = torch.sqrt(grid[:,-1])\n",
    "    v = s**2\n",
    "    r = grid**2/(v-grid)\n",
    "    p_nb = grid/v\n",
    "    \n",
    "    w_r,r_r, p_nb_r, grid_r, logmean_cond_r,logvar_cond_r = w.numpy(),\\\n",
    "                                                             r.numpy(),\\\n",
    "                                                                p_nb.numpy(),\\\n",
    "                                                                    grid.numpy(),\\\n",
    "                                                                        logmean_cond.numpy(),\\\n",
    "                                                                            logvar_cond.numpy()\n",
    "\n",
    "    return(w_r,r_r, p_nb_r, grid_r, logmean_cond_r,logvar_cond_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLd4YDZm2phg"
   },
   "source": [
    "## Create adata object to store counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1663796404757,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "MMI9H0nndgPd"
   },
   "outputs": [],
   "source": [
    "def make_adata_object(bursty_counts,cells_per_ct,marker_annotations):\n",
    "  cell_type_names = [f'CT{i}' for i in range(len(cells_per_ct))]\n",
    "  cell_types = []\n",
    "\n",
    "  for i,ct in enumerate(cell_type_names):\n",
    "    cell_types = cell_types + [ct]*int(cells_per_ct[i])\n",
    "\n",
    "  adata_unspliced = anndata.AnnData(bursty_counts[:,:,0])\n",
    "  adata_spliced = anndata.AnnData(bursty_counts[:,:,1])\n",
    "  adata_unspliced.var_names = adata_unspliced.var_names + '-u'\n",
    "  adata_spliced.var['Spliced']   = True\n",
    "  adata_unspliced.var['Spliced'] = False\n",
    "  adata = anndata.concat([adata_unspliced,adata_spliced],axis=1)\n",
    "  adata.obs['Cell Type'] = cell_types\n",
    "  adata.var['Marker Annotation'] = list(marker_annotations)*2\n",
    "\n",
    "  # normalize and such idk \n",
    "  adata.layers['counts'] = adata.X.copy()\n",
    "  adata = adata[adata.X.sum(axis=1) > 0]\n",
    "\n",
    "  sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "  sc.pp.log1p(adata)\n",
    "\n",
    "  return(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPtefPxEmXzz"
   },
   "source": [
    "-----\n",
    "\n",
    "## Now generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yaNUx1c0jW2g"
   },
   "outputs": [],
   "source": [
    "num_ct_list = [5]\n",
    "num_mg_list = [50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 325909,
     "status": "ok",
     "timestamp": 1663796738649,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "boF0TPMr_KzT",
    "outputId": "f0e6b6a1-ef39-45ea-968b-aa8d829faed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 5 cell types\n",
      "Cell type  0\n",
      "Cell type  1\n",
      "Cell type  2\n",
      "Cell type  3\n",
      "Cell type  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-26a4544b655e>:8: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata_unspliced = anndata.AnnData(bursty_counts[:,:,0])\n",
      "<ipython-input-15-26a4544b655e>:9: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata_spliced = anndata.AnnData(bursty_counts[:,:,1])\n",
      "/home/tara/.local/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "## BURSTY PRODUCTION \n",
    "# num_ct_list = [10,15,20]\n",
    "# num_mg_list = [50,60,60]\n",
    "\n",
    "for i,ct in enumerate(num_ct_list):\n",
    "  N_mg = num_mg_list[i]\n",
    "  print(f'working on {ct} cell types')\n",
    "  bursty_counts,bursty_params,bursty_cells_per_ct,bursty_marker_annotations,bursty_num_mg = generate_count_data(\\\n",
    "                      N_cells = 6000, N_ct = ct, N_g = 2000, distribution = bursty_transcription, model = 'bursty',\n",
    "                      N_mg = N_mg)\n",
    "\n",
    "  adata_bursty = make_adata_object(bursty_counts,bursty_cells_per_ct,bursty_marker_annotations)\n",
    "  adata_bursty.write_loom(f'../data/simulated_data/bursty_{ct}ct.loom')\n",
    "  np.save(f'../data/simulated_data/bursty_{ct}ct_params',bursty_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20192,
     "status": "ok",
     "timestamp": 1663796758838,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "MbOnXHulo18w",
    "outputId": "aabb4c4a-4ccd-475a-b576-31aec6199f43"
   },
   "outputs": [],
   "source": [
    "## CONSTITUTIVE PRODUCTION SIMULATED DATA \n",
    "\n",
    "# num_ct_list = [5,10,15,20]\n",
    "# num_mg_list = [50,50,60,60]\n",
    "num_ct_list = [15]\n",
    "num_mg_list = [60]\n",
    "\n",
    "for i,ct in enumerate(num_ct_list):\n",
    "\n",
    "  N_mg = num_mg_list[i]\n",
    "  print(f'working on {ct} cell types')\n",
    "\n",
    "  const_counts,const_params,const_cells_per_ct,const_marker_annotations,const_num_mg = generate_count_data(N_cells = 6000, N_ct = ct, N_g = 2000, distribution = constitutive_transcription, model = 'const',\n",
    "                                                                                          N_mg = N_mg )\n",
    "  adata_const = make_adata_object(const_counts,const_cells_per_ct,const_marker_annotations)\n",
    "\n",
    "  adata_const.write_loom(f'../data/simulated_data/const_{ct}ct.loom')\n",
    "  np.save(f'../data/simulated_data/const_{ct}ct_params',const_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26571,
     "status": "ok",
     "timestamp": 1663796785404,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "MnRBeNWwBku2",
    "outputId": "aca120e5-3240-40f6-a348-493edcf383cc"
   },
   "outputs": [],
   "source": [
    "# BVNB DATA\n",
    "\n",
    "num_ct_list = [5,10,15,20]\n",
    "num_mg_list = [50,50,60,60]\n",
    "\n",
    "for i,ct in enumerate(num_ct_list):\n",
    "\n",
    "  N_mg = num_mg_list[i]\n",
    "  print(f'working on {ct} cell types')\n",
    "\n",
    "  BVNB_counts,BVNB_params,BVNB_cells_per_ct,BVNB_marker_annotations,BVNB_num_mg =\\\n",
    "   generate_count_data(N_cells = 6000, N_ct = ct, N_g = 2000, \\\n",
    "                       distribution = BVNB, model = 'BVNB', N_mg = N_mg )\n",
    "  adata_BVNB = make_adata_object(BVNB_counts,BVNB_cells_per_ct,BVNB_marker_annotations)\n",
    "\n",
    "  adata_BVNB.write_loom(f'../data/simulated_data/BVNB_{ct}ct.loom')\n",
    "  np.save(f'../data/simulated_data/BVNB_{ct}ct_params',BVNB_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1663697064152,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "kK9TVaw5EaV5",
    "outputId": "9992c536-95c6-4df9-8285-934b15565a75"
   },
   "outputs": [],
   "source": [
    "BVNB_params[:,:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-7AyxfeM6dV"
   },
   "source": [
    "# QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi3RmZuBM78i"
   },
   "source": [
    "gg 220915 stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNCGGZ1VNGW7"
   },
   "source": [
    "## Constitutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOceU0sSM7Wx"
   },
   "outputs": [],
   "source": [
    "adata_const.obs['Cell Type'] = pd.Categorical(adata_const.obs['Cell Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODqp2wvvNXjG",
    "outputId": "ef83fb85-9e02-48b4-92b6-f9664ea76a7e"
   },
   "outputs": [],
   "source": [
    "adata_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPMJmrhINeHw"
   },
   "outputs": [],
   "source": [
    "S = adata_const.layers['counts'][:,adata_const.var['Spliced']]\n",
    "U = adata_const.layers['counts'][:,~adata_const.var['Spliced']]\n",
    "ct = adata_const.obs['Cell Type'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMxQ8dqmONK-"
   },
   "outputs": [],
   "source": [
    "Smean = []\n",
    "Umean = []\n",
    "Svar = []\n",
    "Uvar = []\n",
    "for ct_ in range(5):\n",
    "    Smean.append(S[ct==f'CT{ct_}',:].mean(0))\n",
    "    Umean.append(U[ct==f'CT{ct_}',:].mean(0))\n",
    "    Svar.append(S[ct==f'CT{ct_}',:].var(0))\n",
    "    Uvar.append(U[ct==f'CT{ct_}',:].var(0))\n",
    "Smean = np.asarray(Smean)\n",
    "Umean = np.asarray(Umean)\n",
    "Svar = np.asarray(Svar)\n",
    "Uvar = np.asarray(Uvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "oxrWojqIOmcg",
    "outputId": "d4facb0d-75bc-4de8-983c-45df4df14782"
   },
   "outputs": [],
   "source": [
    "plt.scatter(Smean.flatten(),1/10**const_params[:,:,1].flatten())\n",
    "plt.scatter(Umean.flatten(),1/(10**const_params[:,:,0]).flatten(),alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Gn22DgWOnrMB",
    "outputId": "d5f048d9-2f05-4de4-e591-c99c197f13ee"
   },
   "outputs": [],
   "source": [
    "plt.scatter(Svar.flatten(),1/10**const_params[:,:,1].flatten())\n",
    "plt.scatter(Uvar.flatten(),1/(10**const_params[:,:,0]).flatten(),alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehlNLd6vPv6J"
   },
   "source": [
    "that's ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjZGIyMfPzuR"
   },
   "outputs": [],
   "source": [
    "for ct in range(5):\n",
    "  assert((const_marker_annotations==ct).sum()==const_num_mg[ct])\n",
    "assert((const_marker_annotations==-1).sum()==2000-const_num_mg.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au-3wlj8YZjN"
   },
   "source": [
    "## BVNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttMT30yXOFVN"
   },
   "outputs": [],
   "source": [
    "adata_BVNB.obs['Cell Type'] = pd.Categorical(adata_BVNB.obs['Cell Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSt164utOFXi",
    "outputId": "0f2c069f-ba97-43a2-eb1d-b6939c6b4a2d"
   },
   "outputs": [],
   "source": [
    "adata_BVNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9Ub9nd2OFbL"
   },
   "outputs": [],
   "source": [
    "S = adata_BVNB.layers['counts'][:,adata_BVNB.var['Spliced']]\n",
    "U = adata_BVNB.layers['counts'][:,~adata_BVNB.var['Spliced']]\n",
    "ct = adata_BVNB.obs['Cell Type'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtM_qYNVYggH"
   },
   "outputs": [],
   "source": [
    "Smean = []\n",
    "Umean = []\n",
    "Svar = []\n",
    "Uvar = []\n",
    "for ct_ in range(5):\n",
    "    Smean.append(S[ct==f'CT{ct_}',:].mean(0))\n",
    "    Umean.append(U[ct==f'CT{ct_}',:].mean(0))\n",
    "    Svar.append(S[ct==f'CT{ct_}',:].var(0))\n",
    "    Uvar.append(U[ct==f'CT{ct_}',:].var(0))\n",
    "Smean = np.asarray(Smean)\n",
    "Umean = np.asarray(Umean)\n",
    "Svar = np.asarray(Svar)\n",
    "Uvar = np.asarray(Uvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "p5PBfrQbnyuh",
    "outputId": "b95769b9-d5df-4ded-cb87-b0a42e7b8049"
   },
   "outputs": [],
   "source": [
    "alpha_ = BVNB_params[:,:,0]\n",
    "gamma_ = 10**BVNB_params[:,:,2]\n",
    "beta_ = 10**BVNB_params[:,:,1]\n",
    "plt.loglog(Smean.flatten(),(alpha_/gamma_).flatten(),'.')\n",
    "plt.loglog(Umean.flatten(),(alpha_/beta_).flatten(),'.',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "S3ODaBJhoGTK",
    "outputId": "ee73ae97-55df-44b7-92f7-5caeafdf476f"
   },
   "outputs": [],
   "source": [
    "plt.loglog(Svar.flatten(),(alpha_/gamma_ * (1+1/gamma_)).flatten(),'.')\n",
    "plt.loglog(Uvar.flatten(),(alpha_/beta_ * (1+1/beta_)).flatten(),'.',alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GN5chMWouHi"
   },
   "source": [
    "This doesn't prove that cell types are correct but it's a start. looks ðŸ‘Œ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMh8e8qxriRi"
   },
   "outputs": [],
   "source": [
    "for ct in range(5):\n",
    "  assert((const_marker_annotations==ct).sum()==const_num_mg[ct])\n",
    "assert((const_marker_annotations==-1).sum()==2000-const_num_mg.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muXoiitDrKM7"
   },
   "source": [
    "## Bursty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWIhdP92rNFN"
   },
   "outputs": [],
   "source": [
    "adata_bursty.obs['Cell Type'] = pd.Categorical(adata_bursty.obs['Cell Type'])\n",
    "S = adata_bursty.layers['counts'][:,adata_bursty.var['Spliced']]\n",
    "U = adata_bursty.layers['counts'][:,~adata_bursty.var['Spliced']]\n",
    "ct = adata_bursty.obs['Cell Type'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzleWos0rNHu"
   },
   "outputs": [],
   "source": [
    "Smean = []\n",
    "Umean = []\n",
    "Svar = []\n",
    "Uvar = []\n",
    "for ct_ in range(5):\n",
    "    Smean.append(S[ct==f'CT{ct_}',:].mean(0))\n",
    "    Umean.append(U[ct==f'CT{ct_}',:].mean(0))\n",
    "    Svar.append(S[ct==f'CT{ct_}',:].var(0))\n",
    "    Uvar.append(U[ct==f'CT{ct_}',:].var(0))\n",
    "Smean = np.asarray(Smean)\n",
    "Umean = np.asarray(Umean)\n",
    "Svar = np.asarray(Svar)\n",
    "Uvar = np.asarray(Uvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "Z3yiB5JyrNJ8",
    "outputId": "1a1f03fd-47da-442e-beb9-d26e27353f98"
   },
   "outputs": [],
   "source": [
    "b_ = 10**bursty_params[:,:,0]\n",
    "gamma_ = 10**bursty_params[:,:,2]\n",
    "beta_ = 10**bursty_params[:,:,1]\n",
    "plt.loglog(Smean.flatten(),(b_/gamma_).flatten(),'.')\n",
    "plt.loglog(Umean.flatten(),(b_/beta_).flatten(),'.',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "mfcsMHIKruU2",
    "outputId": "ea42c7fb-ddec-41c2-df67-b25035aebffb"
   },
   "outputs": [],
   "source": [
    "plt.loglog(Svar.flatten(),(b_/gamma_*(1+b_*beta_/(beta_+gamma_))).flatten(),'.')\n",
    "plt.loglog(Uvar.flatten(),(b_/beta_*(1+b_)).flatten(),'.',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5MmYLpWrNNX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGD-G5MXiYCc"
   },
   "source": [
    "# Visualize Cell type clusters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPFymN-Io0W3"
   },
   "source": [
    "## Constitutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSHZqa4kqhSL",
    "outputId": "18c94952-848a-4889-890a-b5d91cbd18a1"
   },
   "outputs": [],
   "source": [
    "name = 'const_5ct'\n",
    "\n",
    "adata = anndata.read_loom(f'../data/simulated_data/{name}.loom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xp9fSclJ4q-O"
   },
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20)\n",
    "sc.tl.leiden(adata, resolution = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "hrDbjJ7b5SdK",
    "outputId": "9261bd10-d1f9-47cf-c83a-1811f3b7fed9"
   },
   "outputs": [],
   "source": [
    "# should see cell types :D \n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=['Cell Type','leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "qaqyGzPu7Kfu",
    "outputId": "da2bf2c2-7afe-4b65-a52c-1ca45d0aaa31"
   },
   "outputs": [],
   "source": [
    "sc.pl.pca(adata,color='Cell Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY2sJbGEo1yi"
   },
   "source": [
    "## BVNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gf-a3pu4MesZ",
    "outputId": "620cb7db-e79f-4bd6-911d-710e467ced5a"
   },
   "outputs": [],
   "source": [
    "name = 'BVNB_5ct'\n",
    "adata = anndata.read_loom(f'../data/simulated_data/{name}.loom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CLQsmZto4BN"
   },
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata, n_neighbors=25, n_pcs=20)\n",
    "sc.tl.leiden(adata, resolution = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DYrX3W9pbU6"
   },
   "source": [
    "suspicious. what's the deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "hhsjH_jLo5Lq",
    "outputId": "b29d3d84-3e12-470d-d392-0c15364b08f8"
   },
   "outputs": [],
   "source": [
    "# should see cell types :D \n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=['Cell Type','leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "0uJO5qqBo6O6",
    "outputId": "2729986d-cc2f-488d-ab07-2623f9bbf27c"
   },
   "outputs": [],
   "source": [
    "sc.pl.pca(adata,color='Cell Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX7Jj3U8rIw-"
   },
   "source": [
    "## Bursty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUfGpB2go7RS",
    "outputId": "f8aca1a1-1a0f-420e-9dcf-fe59d0c23180"
   },
   "outputs": [],
   "source": [
    "name = 'bursty_5ct'\n",
    "\n",
    "adata = anndata.read_loom(f'../data/simulated_data/{name}.loom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcib-wxrr96x"
   },
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata, n_neighbors=50, n_pcs=20)\n",
    "sc.tl.leiden(adata, resolution = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiSEgoEgshNg"
   },
   "source": [
    "Wacky. Maybe bc of def of `adata.X`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "RAGuxw3Jr_TV",
    "outputId": "2ee3b800-567c-4f2e-ed08-28d7f5ddc63d"
   },
   "outputs": [],
   "source": [
    "# should see cell types :D \n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=['Cell Type','leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "6HnZlarBsAWZ",
    "outputId": "a9daf1a5-1efa-4683-b306-5acda0e87eec"
   },
   "outputs": [],
   "source": [
    "sc.pl.pca(adata,color='Cell Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tx6R7KowsBk3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
