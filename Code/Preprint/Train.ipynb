{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LyHDS0r64Po"
   },
   "source": [
    "# Train Models on Various Datasets\n",
    "\n",
    "This notebook contains functions to train models and stores results needed for analysis. \n",
    "\n",
    "\n",
    "It compares models: \n",
    "\n",
    "1. Bursty model of transcription (nnNB), full data\n",
    "2. Constitutive model of transcription (Poisson), full data\n",
    "3. Bivariate negative binomial model (BVNB or Extrinsic model), full data\n",
    "4. \"vanilla scVI\" (negative binomial likelihoods), full data data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It outputs and stores a results dictionary that contains for each of the setups:\n",
    "\n",
    "1. X_10: latent space with dimension 10\n",
    "2. reconstructed parameters: means and dispersions\n",
    "3. normalized/unscaled reconstructed means\n",
    "3. reconstruction loss over training epochs train/test\n",
    "5. final reconstruction loss on test/train data\n",
    "4. runtime\n",
    "\n",
    "\n",
    "Analysis functions are not included in this training notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16772,
     "status": "ok",
     "timestamp": 1665091829735,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "Dx9K8ecWF2FN",
    "outputId": "18397fb0-b943-41f0-c994-0641d6239ddc"
   },
   "outputs": [],
   "source": [
    "# # mount drive \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd drive/MyDrive/grad/scBIVI/GCCCP_2021/Code/Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rOMjTFRNFv0S"
   },
   "outputs": [],
   "source": [
    "# clone the repo -- private right now -- if necessary\n",
    "#!git clone https://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@github.com/pachterlab/GCCCP_2021.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NjOTtMjv63GY"
   },
   "outputs": [],
   "source": [
    "# install necessary pacakges\n",
    "# %%capture\n",
    "# !pip install scanpy -q\n",
    "# !pip install scvi-tools==0.18.0 -q\n",
    "# !pip install loompy -q\n",
    "# !pip install leidenalg -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2099,
     "status": "ok",
     "timestamp": 1665091861095,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "YTE6OfMK9PKZ",
    "outputId": "ca8f59f3-0be8-44c7-a945-5324e710cc82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check GPU availability\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "memory_used = torch.cuda.memory_allocated()\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9pkgIX6swDe9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/tara/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/home/tara/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "import time, gc\n",
    "\n",
    "# add module paths to sys path\n",
    "import sys\n",
    "sys.path.insert(0, '../Code/BIVI/')\n",
    "sys.path.insert(0, '../BIVI/')\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# to save results\n",
    "import pickle\n",
    "\n",
    "# scvi\n",
    "import anndata\n",
    "import scvi\n",
    "\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7682,
     "status": "ok",
     "timestamp": 1665091873071,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "JsCFILc9CiWj",
    "outputId": "e1aa28f3-630a-43b2-cbeb-df3a5b426388"
   },
   "outputs": [],
   "source": [
    "# import biVI scripts\n",
    "import biVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0lQ5lR7XUHd"
   },
   "source": [
    "# Load in data \n",
    "\n",
    "\n",
    "Change data name to test out different simulated datasets with varying number of celltypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6004,
     "status": "ok",
     "timestamp": 1665091879064,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "SHnXm3Pq6WCU",
    "outputId": "be89c4f1-9aba-4fe8-d077-edfa211a07ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "name = 'bursty_20ct_many'\n",
    "\n",
    "# change to hdf5 file if that is what you store data as\n",
    "adata = anndata.read_loom(f'../../data/simulated_data/{name}.loom')\n",
    "\n",
    "if 'gene_name' in adata.var.columns:\n",
    "    adata.var_names = adata.var['gene_name'].to_list()\n",
    "\n",
    "# can change as necessary for data. \n",
    "adata.obs['Cluster'] = adata.obs['Cell Type']\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dxjYlTsdc9vO"
   },
   "outputs": [],
   "source": [
    "#Set up train/test data splits with 5-fold split\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "skf_splits = skf.split(adata, adata.obs['Cluster'])\n",
    "\n",
    "# Use last of the K-fold splits\n",
    "for k, (train_index, test_index) in enumerate(skf_splits):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1665091879066,
     "user": {
      "displayName": "Maria Carilli",
      "userId": "07753124307568175110"
     },
     "user_tz": 420
    },
    "id": "0tRntI7mxGXc",
    "outputId": "70415db8-f784-4d08-96bb-870a6c9a674c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 8000 cells, testing on 2000 cells\n"
     ]
    }
   ],
   "source": [
    "print(f'training on {len(train_index)} cells, testing on {len(test_index)} cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'biVI' from '/home/tara/maria/scBIVI/GCCCP_2021/Code/Preprint/../BIVI/biVI.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(biVI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data and training and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "biVI.biVI.setup_anndata(adata,layer=\"counts\")\n",
    "\n",
    "model_args = {    'n_latent'     : 10,\n",
    "                  'n_layers'     : 3,\n",
    "                  'dispersion'   : 'gene',\n",
    "                  'n_hidden'     : 128,\n",
    "                  'dropout_rate' :  0.1,\n",
    "                  'log_variational'    :  True,\n",
    "                  'latent_distribution':  'normal',\n",
    "                  'decoder_type' : 'linear'\n",
    "                  }\n",
    "\n",
    "# training plan parameters\n",
    "max_epochs = 10\n",
    "\n",
    "plan_kwargs = {'lr' : 0.0001,\n",
    "               'n_epochs_kl_warmup' : max_epochs/2,\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_input': 4000, 'n_hidden': 128, 'n_latent': 10, 'n_layers': 3, 'dropout_rate': 0.1, 'dispersion': 'gene', 'latent_distribution': 'normal', 'log_variational': True}\n",
      "Initiating biVAE\n",
      "Mode: Bursty, Decoder: linear\n"
     ]
    }
   ],
   "source": [
    "model = biVI.biVI(adata, mode = 'Bursty', **model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [00:46<00:00,  4.68s/it, loss=5.35e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [00:46<00:00,  4.64s/it, loss=5.35e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "start = time.time()\n",
    "model.train(max_epochs = max_epochs,\n",
    "                #early_stopping_monitor = [\"reconstruction_loss_validation\"],\n",
    "                train_size = 0.9,\n",
    "                check_val_every_n_epoch  = 1,\n",
    "#                 metrics_to_monitor = ['reconstruction_loss'],\n",
    "                plan_kwargs = plan_kwargs)\n",
    "\n",
    "    \n",
    "runtime     = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=4000, bias=False)\n",
      "  (1): BatchNorm1d(4000, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (2): None\n",
      "  (3): None\n",
      "  (4): None\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[ 0.0712, -0.1953, -0.0636,  ..., -0.2546, -0.2764, -0.0012],\n",
      "        [ 0.2596,  0.0371, -0.0907,  ...,  0.0831,  0.1360,  0.1692],\n",
      "        [-0.1083, -0.2500, -0.2695,  ...,  0.3289,  0.0233,  0.1660],\n",
      "        ...,\n",
      "        [ 0.0644, -0.1736, -0.2278,  ...,  0.1830,  0.0541, -0.1908],\n",
      "        [-0.0281,  0.1622,  0.3102,  ..., -0.2671,  0.1538, -0.0209],\n",
      "        [-0.1800, -0.2243, -0.2598,  ..., -0.0422,  0.1482, -0.2860]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "’------’\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.module.decoder.factor_regressor.fc_layers.named_children():\n",
    "    if not name.startswith(\"params\"):\n",
    "        print(name)\n",
    "        print(module)\n",
    "        print(module[0].weight)\n",
    "        print(\"’------’\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_encoder\n",
      "Encoder(\n",
      "  (encoder): FCLayers(\n",
      "    (fc_layers): Sequential(\n",
      "      (Layer 0): Sequential(\n",
      "        (0): Linear(in_features=4000, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): None\n",
      "        (3): ReLU()\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Layer 1): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): None\n",
      "        (3): ReLU()\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Layer 2): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): None\n",
      "        (3): ReLU()\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mean_encoder): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (var_encoder): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "’------’\n",
      "l_encoder\n",
      "Encoder(\n",
      "  (encoder): FCLayers(\n",
      "    (fc_layers): Sequential(\n",
      "      (Layer 0): Sequential(\n",
      "        (0): Linear(in_features=4000, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): None\n",
      "        (3): ReLU()\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mean_encoder): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (var_encoder): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "’------’\n",
      "decoder\n",
      "LinearDecoderSCVI(\n",
      "  (factor_regressor): FCLayers(\n",
      "    (fc_layers): Sequential(\n",
      "      (Layer 0): Sequential(\n",
      "        (0): Linear(in_features=10, out_features=4000, bias=False)\n",
      "        (1): BatchNorm1d(4000, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): None\n",
      "        (3): None\n",
      "        (4): None\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (px_dropout_decoder): FCLayers(\n",
      "    (fc_layers): Sequential(\n",
      "      (Layer 0): Sequential(\n",
      "        (0): Linear(in_features=10, out_features=4000, bias=False)\n",
      "        (1): BatchNorm1d(4000, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): None\n",
      "        (3): None\n",
      "        (4): None\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "’------’\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.module.named_children():\n",
    "    if not name.startswith(\"params\"):\n",
    "        print(name)\n",
    "        print(module)\n",
    "        print(\"’------’\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuWAkvshCjua"
   },
   "source": [
    "-----\n",
    "\n",
    "\n",
    "# Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DoSUe5ih2f0F"
   },
   "outputs": [],
   "source": [
    "# # if anything goes wrong in training, this will catch where it happens\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# # compare setups\n",
    "# def compare_setups(adata, setups, results_dict, hyperparameters, train_index = train_index, test_index = test_index):\n",
    "#   ''' Runs scBIVI on adata for listed setups in setups given hyperparameters, stores outputs in results_dict. \n",
    "#       Train index and test index are defined globally -- could be nice to pass these in as well? \n",
    "#   ''' \n",
    "\n",
    "#   lr = hyperparameters['lr']\n",
    "#   max_epochs = hyperparameters['max_epochs']\n",
    "#   n_hidden = hyperparameters['n_hidden']\n",
    "#   n_layers = hyperparameters['n_layers']\n",
    "\n",
    "  \n",
    "#   for setup in setups:\n",
    "#     print(setup)\n",
    "#     method,n_latent,constant, = setup.split(\"-\")\n",
    "#     n_latent = int(n_latent)\n",
    "\n",
    "#     # test using only spliced or unspliced in vanilla scVI\n",
    "#     if '.S' in method:\n",
    "#       adata_in = adata[:,adata.var['Spliced']==1]\n",
    "#       print('spliced')\n",
    "#     elif '.U' in method:\n",
    "#       adata_in = adata[:,adata.var['Spliced']==0]\n",
    "#       print('unspliced')\n",
    "#     else:\n",
    "#       adata_in = adata.copy()\n",
    "#     print(adata_in.X.shape)\n",
    "#     #biVI.biVI.setup_anndata(adata_in,layer=\"counts\")\n",
    "#     #categorical_covariate_keys=[\"cell_source\", \"donor\"],\n",
    "#     #continuous_covariate_keys=[\"percent_mito\", \"percent_ribo\"])\n",
    "\n",
    "    \n",
    "#     train_adata, test_adata = adata_in[train_index], adata_in[test_index]\n",
    "#     train_adata = train_adata.copy()\n",
    "#     test_adata = test_adata.copy()\n",
    "#     if 'vanilla' in method:\n",
    "#         scvi.model.SCVI.setup_anndata(test_adata,layer=\"counts\")\n",
    "#         scvi.model.SCVI.setup_anndata(train_adata,layer=\"counts\")\n",
    "#     else:\n",
    "#         biVI.biVI.setup_anndata(test_adata,layer=\"counts\")\n",
    "#         biVI.biVI.setup_anndata(train_adata,layer=\"counts\")\n",
    "    \n",
    "\n",
    "#     ## Set model parameters\n",
    "#     model_args = {\n",
    "#                   'n_latent'     : n_latent,\n",
    "#                   'n_layers'     : n_layers,\n",
    "#                   'dispersion'   : 'gene',\n",
    "#                   'n_hidden'     : n_hidden,\n",
    "#                   'dropout_rate' :  0.1,\n",
    "#                   'gene_likelihood'    :  'nb',\n",
    "#                   'log_variational'    :  True,\n",
    "#                   'latent_distribution':  'normal',\n",
    "#                   }\n",
    "#     #model_args.update(additional_kwargs)\n",
    "\n",
    "#     ## Create model\n",
    "#     if method == 'NBcorr':\n",
    "#         model = biVI.biVI(train_adata,mode='NBcorr',**model_args)\n",
    "#     elif method == 'NBuncorr':\n",
    "#         model = biVI.biVI(train_adata,mode='NBuncorr',**model_args)\n",
    "#     elif method == 'Poisson':\n",
    "#         model = biVI.biVI(train_adata,mode='Poisson',**model_args)\n",
    "#     elif method == 'Bursty':\n",
    "#         model = biVI.biVI(train_adata,mode='Bursty',**model_args)\n",
    "#     elif method == 'vanilla.U':\n",
    "#         model_args['gene_likelihood'] = 'nb'\n",
    "#         model = scvi.model.SCVI(train_adata,**model_args)\n",
    "#     elif method == 'vanilla.S':\n",
    "#         model_args['gene_likelihood'] = 'nb'\n",
    "#         model = scvi.model.SCVI(train_adata,**model_args)\n",
    "#     elif method == 'vanilla.full':\n",
    "#         model_args['gene_likelihood'] = 'nb'\n",
    "#         model = scvi.model.SCVI(train_adata,**model_args)\n",
    "#     elif method == 'vanilla.U.P':\n",
    "#         model_args['gene_likelihood'] = 'poisson'\n",
    "#         model = scvi.model.SCVI(train_adata,**model_args)\n",
    "#     elif method == 'vanilla.S.P':\n",
    "#         model_args['gene_likelihood'] = 'poisson'\n",
    "#         model = scvi.model.SCVI(train_adata,**model_args)\n",
    "#     elif method == 'vanilla.full.P':\n",
    "#         model_args['gene_likelihood'] = 'poisson'\n",
    "#         model = scvi.model.SCVI(train_adata,**model_args)\n",
    "#     else:\n",
    "#         raise Exception('Input valid scVI model')\n",
    "\n",
    "#     ## Train model\n",
    "#     plan_kwargs = {'lr' : lr,\n",
    "#                    'n_epochs_kl_warmup' : max_epochs/2,\n",
    "#                    }\n",
    "    \n",
    "#     start = time.time()\n",
    "#     model.train(max_epochs = max_epochs,\n",
    "#                 #early_stopping_monitor = [\"reconstruction_loss_validation\"],\n",
    "#                 train_size = 0.9,\n",
    "#                 check_val_every_n_epoch  = 1,\n",
    "# #                 metrics_to_monitor = ['reconstruction_loss'],\n",
    "#                 plan_kwargs = plan_kwargs)\n",
    "\n",
    "    \n",
    "#     runtime     = time.time() - start\n",
    "#     memory_used = torch.cuda.memory_allocated()\n",
    "#     results_dict[setup]['runtime'].append(runtime)\n",
    "\n",
    "#     ## Save training history\n",
    "#     df_history = {'reconstruction_error_test_set' : [model.history['reconstruction_loss_train']],\n",
    "#                   'reconstruction_error_train_set': [model.history['reconstruction_loss_validation']]}\n",
    "    \n",
    "#     results_dict[setup]['df_history'] = df_history\n",
    "\n",
    "\n",
    "#     ## Get reconstruction loss on test data\n",
    "#     test_error  = model.get_reconstruction_error(test_adata)\n",
    "#     train_error = model.get_reconstruction_error(train_adata)\n",
    "#     results_dict[setup]['recon_error'].append(np.array([train_error,test_error]))\n",
    "\n",
    "\n",
    "#     results_dict[setup]['params'] = model.get_likelihood_parameters(adata)\n",
    "\n",
    "#     ## Extract the embedding space for scVI\n",
    "#     X_out_full = model.get_latent_representation(adata_in)\n",
    "\n",
    "#     adata.obsm[f'X_{method}'] = X_out_full\n",
    "#     results_dict[setup][f'X_{n_latent}'] = X_out_full\n",
    "\n",
    "#     del model\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "  \n",
    "#   return(results_dict,adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spZ0k7hG918d"
   },
   "source": [
    "# Compare Distributions\n",
    "\n",
    "\n",
    "Can change various training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AvsaCvPX98Ec"
   },
   "outputs": [],
   "source": [
    "#seed should not matter, but this seed works well\n",
    "# scvi._settings.ScviConfig.seed=(8675309)\n",
    "# torch.manual_seed(8675309)\n",
    "# # np.seed(8675309)\n",
    "# np.random.seed(8675309)\n",
    "\n",
    "# # Hyper-parameters\n",
    "# hyperparameters = { 'lr'       : 1e-3,\n",
    "#         'max_epochs' : 10, \n",
    "#         'n_hidden' : 128,\n",
    "#         'n_layers' : 3 }\n",
    "\n",
    "# z  = 10\n",
    "# constant = 'NAS_SHAPE'\n",
    "\n",
    "# setups = [\n",
    "# #           f'vanilla.U-{z}-{constant}',\n",
    "# #           f'vanilla.S-{z}-{constant}',\n",
    "# #           f'vanilla.full-{z}-{constant}',\n",
    "# #           f'vanilla.U.P-{z}-{constant}',\n",
    "# #           f'vanilla.S.P-{z}-{constant}',\n",
    "# #           f'vanilla.full.P-{z}-{constant}',\n",
    "#           f'Poisson-{z}-{constant}',\n",
    "#           f'NBcorr-{z}-{constant}',\n",
    "#           #f'Bursty-{z}-{constant}'\n",
    "#           ]\n",
    "\n",
    "# metrics_list = [f'X_{z}','runtime','df_history','params','recon_error']\n",
    "# results_dict = {setup:{metrics: [] for metrics in metrics_list} for setup in setups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiv2Tvnh-I2k",
    "outputId": "87f0b79d-b582-4f9b-b866-27d9d83b95e6"
   },
   "outputs": [],
   "source": [
    "# results_dict, adata = compare_setups(adata, setups,results_dict,hyperparameters)\n",
    "# results_dict['Cell Type'] = adata.obs['Cell Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = results_dict['Poisson-10-NAS_SHAPE']['df_history']\n",
    "# # sns.lineplot(data=df, \n",
    "# #              x='Epoch', \n",
    "# #              y='Loss', \n",
    "# #              hue = 'Loss Type')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict['Poisson-10-NAS_SHAPE']['params']['mean'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSfIMlvXHZlr"
   },
   "source": [
    "# Save results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZFCx90x8LNOV"
   },
   "outputs": [],
   "source": [
    "# results_file = open(f\"../../results/{name}_results_dict.pickle\", \"wb\")\n",
    "# pickle.dump(results_dict, results_file)\n",
    "# results_file.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
